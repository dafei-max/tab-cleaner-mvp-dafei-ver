"""
é˜¿é‡Œäº‘ Analytics Database å‘é‡æ•°æ®åº“é›†æˆ
ç”¨äºå­˜å‚¨å’Œæ£€ç´¢ OpenGraph æ•°æ®çš„ embedding å‘é‡
"""
import os
import asyncpg
import json
import asyncio
from typing import Dict, List, Optional, Tuple
import numpy as np
from datetime import datetime


def to_vector_str(vec: Optional[List[float]]) -> Optional[str]:
    """
    Convert a Python list[float] into the string format expected by ADBPG's vector(1024) type.
    For example: [0.1, 0.2, 0.3] -> "[0.1,0.2,0.3]".
    If vec is falsy or empty, return None.
    """
    if not vec:
        return None
    return "[" + ",".join(str(float(x)) for x in vec) + "]"

# æ•°æ®åº“è¿æ¥é…ç½®
DB_HOST = os.getenv("ADBPG_HOST", "gp-uf6j424dtk2ww5291o-master.gpdb.rds.aliyuncs.com")
DB_PORT = int(os.getenv("ADBPG_PORT", "5432"))
# æ³¨æ„ï¼šæ•°æ®åº“åç§°ç”±ç¯å¢ƒå˜é‡ ADBPG_DBNAME å†³å®š

# å¦‚æœä½¿ç”¨ Namespaceï¼Œæ•°æ®ä¼šå­˜å‚¨åœ¨å¯¹åº”æ•°æ®åº“çš„ Schema ä¸­
# å®é™…è¡¨è·¯å¾„ = {ADBPG_DBNAME}.{ADBPG_NAMESPACE}.opengraph_items
DB_NAME = os.getenv("ADBPG_DBNAME", "postgres")
DB_USER = os.getenv("ADBPG_USER", "cleantab_db")
DB_PASSWORD = os.getenv("ADBPG_PASSWORD", "CleanTabV5")
NAMESPACE = os.getenv("ADBPG_NAMESPACE", "cleantab")

# è¡¨åï¼ˆæ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼Œé»˜è®¤ä½¿ç”¨ v2 è¡¨ï¼‰
ACTIVE_TABLE_NAME = os.getenv("VECTOR_DB_ACTIVE_TABLE", "opengraph_items_v2")
LEGACY_TABLE_NAME = "opengraph_items"

def _qualified(table_name: str) -> str:
    return f"{NAMESPACE}.{table_name}"

ACTIVE_TABLE = _qualified(ACTIVE_TABLE_NAME)
LEGACY_TABLE = _qualified(LEGACY_TABLE_NAME)

# è¿æ¥æ± 
_pool: Optional[asyncpg.Pool] = None

def _normalize_user_id(user_id: Optional[str]) -> str:
    value = (user_id or "anonymous").strip()
    return value or "anonymous"

def _row_to_dict(row: asyncpg.Record) -> Dict:
    item = dict(row)
    if item.get("text_embedding"):
        item["text_embedding"] = list(item["text_embedding"])
    if item.get("image_embedding"):
        item["image_embedding"] = list(item["image_embedding"])
    if item.get("metadata"):
        item["metadata"] = json.loads(item["metadata"]) if isinstance(item["metadata"], str) else item["metadata"]
    return item

async def _create_index(conn, description: str, sql: str):
    try:
        await conn.execute(sql)
    except Exception as e:
        print(f"[VectorDB] Warning: could not create {description}: {e}")


async def get_pool() -> asyncpg.Pool:
    """è·å–æ•°æ®åº“è¿æ¥æ± ï¼ˆå•ä¾‹ï¼‰"""
    global _pool
    if _pool is None:
        if not DB_HOST:
            raise ValueError("ADBPG_HOST environment variable not set")
        _pool = await asyncpg.create_pool(
            host=DB_HOST,
            port=DB_PORT,
            database=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD,
            min_size=2,
            max_size=10,
            ssl="disable",  # æ ¹æ®ç”¨æˆ·æä¾›çš„è¿æ¥å­—ç¬¦ä¸²
        )
    return _pool


async def close_pool():
    """å…³é—­è¿æ¥æ± """
    global _pool
    if _pool:
        await _pool.close()
        _pool = None


async def drop_table_if_exists():
    """
    æ‰‹åŠ¨åˆ é™¤è¡¨ï¼ˆç”¨äºä¿®å¤çº¦æŸå†²çªé—®é¢˜ï¼‰
    æ³¨æ„ï¼šè¿™ä¼šåˆ é™¤è¡¨ä¸­çš„æ‰€æœ‰æ•°æ®ï¼
    """
    try:
        pool = await get_pool()
        async with pool.acquire() as conn:
            await conn.execute(f"DROP TABLE IF EXISTS {ACTIVE_TABLE} CASCADE;")
            print(f"[VectorDB] âœ“ Dropped table {ACTIVE_TABLE}")
            return True
    except Exception as e:
        print(f"[VectorDB] Error dropping table: {e}")
        import traceback
        traceback.print_exc()
        return False


async def check_table_constraints(conn, table_name: str = ACTIVE_TABLE_NAME) -> Tuple[bool, Optional[str]]:
    """
    æ£€æŸ¥è¡¨çº¦æŸæ˜¯å¦ç¬¦åˆ Greenplum/ADBPG è¦æ±‚
    è¿”å›: (is_valid, error_message)
    """
    try:
        # æ£€æŸ¥ PRIMARY KEY çº¦æŸæ•°é‡
        pk_count = await conn.fetchval(f"""
            SELECT COUNT(*)
            FROM information_schema.table_constraints
            WHERE table_schema = '{NAMESPACE}'
              AND table_name = '{table_name}'
              AND constraint_type = 'PRIMARY KEY';
        """)
        
        # æ£€æŸ¥ UNIQUE çº¦æŸæ•°é‡ï¼ˆä¸åŒ…æ‹¬ PRIMARY KEYï¼‰
        unique_count = await conn.fetchval(f"""
            SELECT COUNT(*)
            FROM information_schema.table_constraints
            WHERE table_schema = '{NAMESPACE}'
              AND table_name = '{table_name}'
              AND constraint_type = 'UNIQUE';
        """)
        
        total_constraints = pk_count + unique_count
        
        if total_constraints > 1:
            # è·å–æ‰€æœ‰çº¦æŸçš„åˆ—ä¿¡æ¯
            constraints_info = await conn.fetch(f"""
                SELECT 
                    tc.constraint_name,
                    tc.constraint_type,
                    string_agg(kcu.column_name, ', ' ORDER BY kcu.ordinal_position) as columns
                FROM information_schema.table_constraints tc
                JOIN information_schema.key_column_usage kcu
                    ON tc.constraint_name = kcu.constraint_name
                    AND tc.table_schema = kcu.table_schema
                WHERE tc.table_schema = '{NAMESPACE}'
                  AND tc.table_name = '{table_name}'
                  AND tc.constraint_type IN ('PRIMARY KEY', 'UNIQUE')
                GROUP BY tc.constraint_name, tc.constraint_type
                ORDER BY tc.constraint_type, tc.constraint_name;
            """)
            
            constraint_details = "\n".join([
                f"  - {row['constraint_type']}: {row['constraint_name']} on ({row['columns']})"
                for row in constraints_info
            ])
            
            error_msg = (
                f"[VectorDB] âœ— Table has {total_constraints} PRIMARY KEY/UNIQUE constraints!\n"
                f"[VectorDB] âœ— Greenplum/ADBPG requires all constraints to share at least one column.\n"
                f"[VectorDB] âœ— Found constraints:\n{constraint_details}\n"
                f"[VectorDB] âœ— Solution: Drop the table and recreate it with only one PRIMARY KEY on the same column set.\n"
                f"[VectorDB] âœ— Run: DROP TABLE IF EXISTS {_qualified(table_name)};"
            )
            return False, error_msg
        
        return True, None
    except Exception as e:
        # å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œå‡è®¾è¡¨ç»“æ„å¯èƒ½æœ‰é—®é¢˜
        return False, f"Failed to check constraints: {e}"


async def init_schema():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
    try:
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            # æ³¨æ„ï¼šåœ¨é˜¿é‡Œäº‘ ADB PostgreSQL ä¸­ï¼ŒNamespace åº”è¯¥é€šè¿‡ API åˆ›å»º
            # å¦‚æœ Namespace å·²é€šè¿‡ API åˆ›å»ºï¼Œå¯¹åº”çš„ Schema ä¼šè‡ªåŠ¨å­˜åœ¨äºå½“å‰è¿æ¥çš„æ•°æ®åº“ä¸­
            # å®é™…æ•°æ®åº“ç”± ADBPG_DBNAME ç¯å¢ƒå˜é‡å†³å®šï¼ˆå¯èƒ½æ˜¯ postgres æˆ– knowledgebaseï¼‰
            # è¿™é‡Œåªæ£€æŸ¥ Schema æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ä¼šæŠ¥é”™ï¼ˆéœ€è¦å…ˆé€šè¿‡ API åˆ›å»º Namespaceï¼‰
            schema_exists = await conn.fetchval(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.schemata 
                    WHERE schema_name = '{NAMESPACE}'
                );
            """)
            
            if not schema_exists:
                error_msg = (
                    f"[VectorDB] âœ— Schema '{NAMESPACE}' does not exist!\n"
                    f"[VectorDB] âœ— In Alibaba Cloud ADB PostgreSQL, Namespace must be created via API first.\n"
                    f"[VectorDB] âœ— Please run: python init_vector.py to create the namespace\n"
                    f"[VectorDB] âœ— Or use the Alibaba Cloud API: CreateNamespace"
                )
                print(error_msg)
                raise ValueError(f"Schema '{NAMESPACE}' does not exist. Please create Namespace via API first.")
            
            print(f"[VectorDB] âœ“ Schema '{NAMESPACE}' exists (Namespace created via API)")
            
            # æ£€æŸ¥ v2 è¡¨æ˜¯å¦å­˜åœ¨
            table_exists = await conn.fetchval(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = '{NAMESPACE}' 
                      AND table_name = '{ACTIVE_TABLE_NAME}'
                );
            """)
            
            if not table_exists:
                await conn.execute(f"""
                    CREATE TABLE {ACTIVE_TABLE} (
                        user_id TEXT NOT NULL,
                        url TEXT NOT NULL,
                        title TEXT,
                        description TEXT,
                        image TEXT,
                        screenshot_image TEXT,
                        site_name TEXT,
                        tab_id INTEGER,
                        tab_title TEXT,
                        text_embedding vector(1024),
                        image_embedding vector(1024),
                        metadata JSONB,
                        -- Caption ç›¸å…³å­—æ®µ
                        image_caption TEXT,
                        caption_embedding vector(1024),
                        dominant_colors TEXT[],
                        style_tags TEXT[],
                        object_tags TEXT[],
                        status TEXT DEFAULT 'active' CHECK (status IN ('active', 'deleted')),
                        deleted_at TIMESTAMP,
                        created_at TIMESTAMP DEFAULT NOW(),
                        updated_at TIMESTAMP DEFAULT NOW(),
                        PRIMARY KEY (user_id, url)
                    );
                """)
                print(f"[VectorDB] âœ“ Created new table: {ACTIVE_TABLE}")
                
                # åˆ›å»º Caption ç›¸å…³ç´¢å¼•
                await _create_index(
                    conn,
                    "dominant_colors GIN index",
                    f"CREATE INDEX idx_{ACTIVE_TABLE_NAME}_dominant_colors_gin ON {ACTIVE_TABLE} USING GIN (dominant_colors);"
                )
                
                await _create_index(
                    conn,
                    "style_tags GIN index",
                    f"CREATE INDEX idx_{ACTIVE_TABLE_NAME}_style_tags_gin ON {ACTIVE_TABLE} USING GIN (style_tags);"
                )
                
                await _create_index(
                    conn,
                    "object_tags GIN index",
                    f"CREATE INDEX idx_{ACTIVE_TABLE_NAME}_object_tags_gin ON {ACTIVE_TABLE} USING GIN (object_tags);"
                )
                
                await _create_index(
                    conn,
                    "caption_embedding index",
                    f"""
                    CREATE INDEX idx_{ACTIVE_TABLE_NAME}_caption_embedding
                    ON {ACTIVE_TABLE}
                    USING ann(caption_embedding)
                    WITH (
                        distancemeasure = cosine,
                        hnsw_m           = 64,
                        pq_enable        = 0
                    );
                    """
                )
                
                await _create_index(
                    conn,
                    "image_caption fulltext index",
                    f"CREATE INDEX idx_{ACTIVE_TABLE_NAME}_image_caption_fts ON {ACTIVE_TABLE} USING GIN (to_tsvector('english', COALESCE(image_caption, '')));"
                )
            else:
                print(f"[VectorDB] âœ“ Table {ACTIVE_TABLE} already exists")
                # ç¡®ä¿ user_id åˆ—å­˜åœ¨
                user_column_exists = await conn.fetchval(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.columns 
                        WHERE table_schema = '{NAMESPACE}'
                          AND table_name = '{ACTIVE_TABLE_NAME}'
                          AND column_name = 'user_id'
                    );
                """)
                if not user_column_exists:
                    raise ValueError(f"[VectorDB] âœ— Table {ACTIVE_TABLE} exists but missing user_id column. Please recreate table manually.")
                
                # æ·»åŠ è½¯åˆ é™¤å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                status_column_exists = await conn.fetchval(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.columns 
                        WHERE table_schema = '{NAMESPACE}'
                          AND table_name = '{ACTIVE_TABLE_NAME}'
                          AND column_name = 'status'
                    );
                """)
                if not status_column_exists:
                    await conn.execute(f"""
                        ALTER TABLE {ACTIVE_TABLE}
                        ADD COLUMN status TEXT DEFAULT 'active' CHECK (status IN ('active', 'deleted'));
                    """)
                    print(f"[VectorDB] âœ“ Added status column to {ACTIVE_TABLE}")
                
                deleted_at_column_exists = await conn.fetchval(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.columns 
                        WHERE table_schema = '{NAMESPACE}'
                          AND table_name = '{ACTIVE_TABLE_NAME}'
                          AND column_name = 'deleted_at'
                    );
                """)
                if not deleted_at_column_exists:
                    await conn.execute(f"""
                        ALTER TABLE {ACTIVE_TABLE}
                        ADD COLUMN deleted_at TIMESTAMP;
                    """)
                    print(f"[VectorDB] âœ“ Added deleted_at column to {ACTIVE_TABLE}")
            
            # åˆ›å»ºå¿…è¦ç´¢å¼•ï¼ˆå¿½ç•¥å·²å­˜åœ¨çš„é”™è¯¯ï¼‰
            await _create_index(
                conn,
                "user_id index",
                f"CREATE INDEX idx_{ACTIVE_TABLE_NAME}_user_id ON {ACTIVE_TABLE}(user_id);"
            )
            
            await _create_index(
                conn,
                "text embedding index",
                f"""
                CREATE INDEX idx_{ACTIVE_TABLE_NAME}_text_embedding
                ON {ACTIVE_TABLE}
                USING ann(text_embedding)
                WITH (
                    distancemeasure = cosine,
                    hnsw_m           = 64,
                    pq_enable        = 0
                );
                """
            )
            
            await _create_index(
                conn,
                "image embedding index",
                f"""
                CREATE INDEX idx_{ACTIVE_TABLE_NAME}_image_embedding
                ON {ACTIVE_TABLE}
                USING ann(image_embedding)
                WITH (
                    distancemeasure = cosine,
                    hnsw_m           = 64,
                    pq_enable        = 0
                );
                """
            )
            
            print(f"[VectorDB] âœ“ Schema initialized for namespace: {NAMESPACE} (table={ACTIVE_TABLE})")
    except Exception as e:
        print(f"[VectorDB] Error initializing schema: {e}")
        import traceback
        traceback.print_exc()
        raise


def _normalize_url_for_storage(url: str) -> str:
    """
    æ ‡å‡†åŒ– URL ç”¨äºå­˜å‚¨å’Œå»é‡ï¼ˆç§»é™¤æŸ¥è¯¢å‚æ•°ã€é”šç‚¹ã€å°¾éšæ–œæ ï¼‰
    
    Args:
        url: åŸå§‹ URL
    
    Returns:
        æ ‡å‡†åŒ–åçš„ URL
    """
    if not url:
        return url
    try:
        from urllib.parse import urlparse, urlunparse
        parsed = urlparse(url)
        # ç§»é™¤æŸ¥è¯¢å‚æ•°ã€é”šç‚¹ã€å°¾éšæ–œæ 
        normalized = urlunparse((
            parsed.scheme,
            parsed.netloc,
            parsed.path.rstrip('/'),
            '',  # params
            '',  # query - ç§»é™¤æŸ¥è¯¢å‚æ•°
            ''   # fragment - ç§»é™¤é”šç‚¹
        )).lower()
        return normalized
    except Exception as e:
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹ URLï¼ˆå°å†™ï¼‰
        return url.lower()


async def upsert_opengraph_item(
    user_id: Optional[str],
    url: str,
    title: Optional[str] = None,
    description: Optional[str] = None,
    image: Optional[str] = None,
    site_name: Optional[str] = None,
    tab_id: Optional[int] = None,
    tab_title: Optional[str] = None,
    text_embedding: Optional[List[float]] = None,
    image_embedding: Optional[List[float]] = None,
    metadata: Optional[Dict] = None,
    # Caption ç›¸å…³å­—æ®µ
    image_caption: Optional[str] = None,
    caption_embedding: Optional[List[float]] = None,
    dominant_colors: Optional[List[str]] = None,
    style_tags: Optional[List[str]] = None,
    object_tags: Optional[List[str]] = None,
) -> bool:
    """
    æ’å…¥æˆ–æ›´æ–° OpenGraph æ•°æ®
    
    âœ… è‡ªåŠ¨å»é‡ï¼šä½¿ç”¨æ ‡å‡†åŒ– URLï¼ˆç§»é™¤æŸ¥è¯¢å‚æ•°ã€é”šç‚¹ï¼‰ä½œä¸ºå”¯ä¸€æ ‡è¯†
    è¿™æ ·å¯ä»¥é¿å…åŒä¸€ä¸ªé¡µé¢å› ä¸ºæŸ¥è¯¢å‚æ•°ä¸åŒè€Œè¢«é‡å¤å­˜å‚¨
    
    Args:
        url: ç½‘é¡µ URLï¼ˆä¼šè‡ªåŠ¨æ ‡å‡†åŒ–ç”¨äºå»é‡ï¼‰
        title: æ ‡é¢˜
        description: æè¿°
        image: å›¾ç‰‡ URL æˆ– Base64ï¼ˆå¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼Œä¸èƒ½æ˜¯æ•°ç»„ï¼‰
        site_name: ç«™ç‚¹åç§°
        tab_id: æ ‡ç­¾é¡µ ID
        tab_title: æ ‡ç­¾é¡µæ ‡é¢˜
        text_embedding: æ–‡æœ¬ embedding å‘é‡ï¼ˆ1024ç»´ï¼‰
        image_embedding: å›¾åƒ embedding å‘é‡ï¼ˆ1024ç»´ï¼‰
        metadata: å…¶ä»–å…ƒæ•°æ®
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        # âœ… æ ‡å‡†åŒ– URL ç”¨äºå»é‡ï¼ˆç§»é™¤æŸ¥è¯¢å‚æ•°ã€é”šç‚¹ã€å°¾éšæ–œæ ï¼‰
        normalized_url = _normalize_url_for_storage(url)
        # âœ… ç±»å‹éªŒè¯å’Œè§„èŒƒåŒ–
        # ç¡®ä¿ image æ˜¯å­—ç¬¦ä¸²ï¼Œä¸æ˜¯æ•°ç»„
        if image is not None:
            if isinstance(image, list):
                # å¦‚æœæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                if len(image) > 0:
                    image = str(image[0]).strip()
                else:
                    image = None
            elif not isinstance(image, str):
                image = str(image).strip() if image else None
            else:
                image = image.strip() if image.strip() else None
        
        # ç¡®ä¿å­—ç¬¦ä¸²å­—æ®µä¸æ˜¯ Noneï¼ˆè½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
        title = str(title).strip() if title else None
        description = str(description).strip() if description else None
        site_name = str(site_name).strip() if site_name else None
        tab_title = str(tab_title).strip() if tab_title else None
        
        # ç¡®ä¿ tab_id æ˜¯æ•´æ•°æˆ– None
        if tab_id is not None:
            try:
                tab_id = int(tab_id)
            except (ValueError, TypeError):
                tab_id = None
        
        user_id = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            # å‡†å¤‡ metadata
            metadata_json = json.dumps(metadata or {})
            
            # å°† embedding åˆ—è¡¨è½¬æ¢ä¸º ADBPG éœ€è¦çš„å­—ç¬¦ä¸²æ ¼å¼
            text_vec = to_vector_str(text_embedding)
            image_vec = to_vector_str(image_embedding)
            caption_vec = to_vector_str(caption_embedding)
            
            # æ£€æŸ¥æ–°å­—æ®µæ˜¯å¦å­˜åœ¨ï¼ˆå‘åå…¼å®¹ï¼‰
            has_caption_fields = await conn.fetchval(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.columns 
                    WHERE table_schema = '{NAMESPACE}'
                      AND table_name = '{ACTIVE_TABLE_NAME}'
                      AND column_name = 'image_caption'
                );
            """)
            
            if has_caption_fields:
                # ä½¿ç”¨æ–°å­—æ®µ
                await conn.execute(f"""
                    INSERT INTO {ACTIVE_TABLE} (
                        user_id, url, title, description, image, site_name,
                        tab_id, tab_title, text_embedding, image_embedding, metadata,
                        image_caption, caption_embedding, dominant_colors, style_tags, object_tags,
                        status, updated_at
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9::vector(1024), $10::vector(1024), $11::jsonb,
                        $12, $13::vector(1024), $14, $15, $16,
                        'active', NOW())
                    ON CONFLICT (user_id, url) DO UPDATE SET
                        title = EXCLUDED.title,
                        description = EXCLUDED.description,
                        image = EXCLUDED.image,
                        site_name = EXCLUDED.site_name,
                        tab_id = EXCLUDED.tab_id,
                        tab_title = EXCLUDED.tab_title,
                        text_embedding = EXCLUDED.text_embedding,
                        image_embedding = EXCLUDED.image_embedding,
                        metadata = EXCLUDED.metadata,
                        image_caption = EXCLUDED.image_caption,
                        caption_embedding = EXCLUDED.caption_embedding,
                        dominant_colors = EXCLUDED.dominant_colors,
                        style_tags = EXCLUDED.style_tags,
                        object_tags = EXCLUDED.object_tags,
                        status = 'active',
                        deleted_at = NULL,
                        updated_at = NOW();
                """, user_id, normalized_url, title, description, image, site_name,
                    tab_id, tab_title, text_vec, image_vec, metadata_json,
                    image_caption, caption_vec, dominant_colors, style_tags, object_tags)
            else:
                # é™çº§åˆ°æ—§ç‰ˆæœ¬ï¼ˆåªä½¿ç”¨ metadataï¼‰
                await conn.execute(f"""
                    INSERT INTO {ACTIVE_TABLE} (
                        user_id, url, title, description, image, site_name,
                        tab_id, tab_title, text_embedding, image_embedding, metadata, 
                        status, updated_at
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9::vector(1024), $10::vector(1024), $11::jsonb, 'active', NOW())
                    ON CONFLICT (user_id, url) DO UPDATE SET
                        title = EXCLUDED.title,
                        description = EXCLUDED.description,
                        image = EXCLUDED.image,
                        site_name = EXCLUDED.site_name,
                        tab_id = EXCLUDED.tab_id,
                        tab_title = EXCLUDED.tab_title,
                        text_embedding = EXCLUDED.text_embedding,
                        image_embedding = EXCLUDED.image_embedding,
                        metadata = EXCLUDED.metadata,
                        status = 'active',
                        deleted_at = NULL,
                        updated_at = NOW();
                """, user_id, normalized_url, title, description, image, site_name,
                    tab_id, tab_title, text_vec, image_vec, metadata_json)
            
            return True
    except Exception as e:
        print(f"[VectorDB] Error upserting item {url[:50]}...: {e}")
        import traceback
        traceback.print_exc()
        return False


async def update_opengraph_item_screenshot(user_id: Optional[str], url: str, screenshot_image: str) -> bool:
    """
    æ›´æ–° OpenGraph item çš„æˆªå›¾å­—æ®µ
    
    Args:
        url: ç½‘é¡µ URL
        screenshot_image: æˆªå›¾çš„ Base64 data URL
    
    Returns:
        æˆåŠŸè¿”å› Trueï¼Œå¤±è´¥è¿”å› False
    """
    try:
        user_id = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            await conn.execute(f"""
                UPDATE {ACTIVE_TABLE}
                SET screenshot_image = $1,
                    updated_at = NOW()
                WHERE user_id = $2 AND url = $3;
            """, screenshot_image, user_id, url)
            
            return True
    except Exception as e:
        print(f"[VectorDB] Error updating screenshot for {url[:50]}...: {e}")
        import traceback
        traceback.print_exc()
        return False


async def get_opengraph_item(user_id: Optional[str], url: str) -> Optional[Dict]:
    """
    æ ¹æ® URL è·å– OpenGraph æ•°æ®ï¼ˆåŒ…æ‹¬ embeddingï¼‰
    
    Args:
        url: ç½‘é¡µ URL
    
    Returns:
        OpenGraph æ•°æ®å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
    """
    try:
        user_id = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            row = await conn.fetchrow(f"""
                SELECT user_id, url, title, description, image, screenshot_image, site_name,
                       tab_id, tab_title, text_embedding, image_embedding, metadata
                FROM {ACTIVE_TABLE}
                WHERE user_id = $1 AND url = $2 AND status = 'active';
            """, user_id, url)
            
            if not row:
                return None
            
            # è½¬æ¢ vector ç±»å‹ä¸ºåˆ—è¡¨
            return _row_to_dict(row)
    except Exception as e:
        print(f"[VectorDB] Error getting item {url[:50]}...: {e}")
        return None


async def get_items_by_urls(user_id: Optional[str], urls: List[str]) -> List[Dict]:
    """
    æ‰¹é‡æ ¹æ® URL åˆ—è¡¨è·å– OpenGraph æ•°æ®ï¼ˆåŒ…æ‹¬ embeddingï¼‰
    
    Args:
        urls: ç½‘é¡µ URL åˆ—è¡¨
    
    Returns:
        OpenGraph æ•°æ®å­—å…¸åˆ—è¡¨
    """
    if not urls:
        return []
    
    try:
        user_id = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            # ä½¿ç”¨ IN æŸ¥è¯¢æ‰¹é‡è·å–ï¼ˆåªè¿”å› active è®°å½•ï¼‰
            placeholders = ','.join([f'${i+1}' for i in range(len(urls))])
            rows = await conn.fetch(f"""
                SELECT user_id, url, title, description, image, screenshot_image, site_name,
                       tab_id, tab_title, text_embedding, image_embedding, metadata
                FROM {ACTIVE_TABLE}
                WHERE user_id = ${len(urls)+1} AND url IN ({placeholders}) AND status = 'active';
            """, *urls, user_id)
            
            results = []
            for row in rows:
                results.append(_row_to_dict(row))
            
            return results
    except Exception as e:
        print(f"[VectorDB] Error getting items by URLs: {e}")
        import traceback
        traceback.print_exc()
        return []


async def search_by_text_embedding(
    user_id: Optional[str],
    query_embedding: List[float],
    top_k: int = 20,
    threshold: float = 0.0
) -> List[Dict]:
    """
    æ ¹æ®æ–‡æœ¬ embedding è¿›è¡Œç›¸ä¼¼åº¦æœç´¢ï¼ˆä¸¥æ ¼æŒ‰ç”¨æˆ·éš”ç¦»ï¼‰
    
    Args:
        user_id: ç”¨æˆ·ID
        query_embedding: æŸ¥è¯¢æ–‡æœ¬çš„ embedding å‘é‡ï¼ˆ1024ç»´ï¼‰
        top_k: è¿”å›å‰ K ä¸ªç»“æœ
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
    
    Returns:
        ç›¸ä¼¼åº¦æ’åºçš„ç»“æœåˆ—è¡¨
    """
    try:
        normalized_user = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            query_vec = to_vector_str(query_embedding)
            
            rows = await conn.fetch(f"""
                SELECT user_id, url, title, description, image, site_name,
                       tab_id, tab_title, text_embedding, image_embedding, metadata,
                       1 - (text_embedding <=> $1::vector(1024)) AS similarity
                FROM {ACTIVE_TABLE}
                WHERE status = 'active'
                  AND user_id = $2
                  AND text_embedding IS NOT NULL
                  AND (1 - (text_embedding <=> $1::vector(1024))) >= $3
                ORDER BY text_embedding <=> $1::vector(1024)
                LIMIT $4;
            """, query_vec, normalized_user, threshold, top_k)
            
            results = []
            for row in rows:
                item = _row_to_dict(row)
                results.append(item)
            
            return results
    except Exception as e:
        print(f"[VectorDB] Error searching by text embedding: {e}")
        import traceback
        traceback.print_exc()
        return []


async def search_by_image_embedding(
    user_id: Optional[str],
    query_embedding: List[float],
    top_k: int = 20,
    threshold: float = 0.0
) -> List[Dict]:
    """
    æ ¹æ®å›¾åƒ embedding è¿›è¡Œç›¸ä¼¼åº¦æœç´¢ï¼ˆä¸¥æ ¼æŒ‰ç”¨æˆ·éš”ç¦»ï¼‰
    
    Args:
        user_id: ç”¨æˆ·ID
        query_embedding: æŸ¥è¯¢å›¾åƒçš„ embedding å‘é‡ï¼ˆ1024ç»´ï¼‰
        top_k: è¿”å›å‰ K ä¸ªç»“æœ
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
    
    Returns:
        ç›¸ä¼¼åº¦æ’åºçš„ç»“æœåˆ—è¡¨
    """
    try:
        normalized_user = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            query_vec = to_vector_str(query_embedding)
            
            rows = await conn.fetch(f"""
                SELECT user_id, url, title, description, image, site_name,
                       tab_id, tab_title, text_embedding, image_embedding, metadata,
                       1 - (image_embedding <=> $1::vector(1024)) AS similarity
                FROM {ACTIVE_TABLE}
                WHERE status = 'active'
                  AND user_id = $2
                  AND image_embedding IS NOT NULL
                  AND (1 - (image_embedding <=> $1::vector(1024))) >= $3
                ORDER BY image_embedding <=> $1::vector(1024)
                LIMIT $4;
            """, query_vec, normalized_user, threshold, top_k)
            
            results = []
            for row in rows:
                item = _row_to_dict(row)
                results.append(item)
            
            return results
    except Exception as e:
        print(f"[VectorDB] Error searching by image embedding: {e}")
        import traceback
        traceback.print_exc()
        return []


async def search_by_caption_embedding(
    user_id: Optional[str],
    query_embedding: List[float],
    top_k: int = 20,
    threshold: float = 0.0
) -> List[Dict]:
    """
    æ ¹æ® Caption embedding è¿›è¡Œç›¸ä¼¼åº¦æœç´¢ï¼ˆä¸¥æ ¼æŒ‰ç”¨æˆ·éš”ç¦»ï¼‰
    
    Args:
        user_id: ç”¨æˆ·ID
        query_embedding: æŸ¥è¯¢æ–‡æœ¬çš„ embedding å‘é‡ï¼ˆ1024ç»´ï¼‰
        top_k: è¿”å›å‰ K ä¸ªç»“æœ
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
    
    Returns:
        ç›¸ä¼¼åº¦æ’åºçš„ç»“æœåˆ—è¡¨
    """
    try:
        normalized_user = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            # æ£€æŸ¥ caption_embedding å­—æ®µæ˜¯å¦å­˜åœ¨
            has_caption_embedding = await conn.fetchval(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.columns 
                    WHERE table_schema = '{NAMESPACE}'
                      AND table_name = '{ACTIVE_TABLE_NAME}'
                      AND column_name = 'caption_embedding'
                );
            """)
            
            if not has_caption_embedding:
                print(f"[VectorDB] caption_embedding column not found, skipping caption embedding search")
                return []
            
            query_vec = to_vector_str(query_embedding)
            
            rows = await conn.fetch(f"""
                SELECT user_id, url, title, description, image, site_name,
                       tab_id, tab_title, text_embedding, image_embedding, metadata,
                       image_caption, caption_embedding, dominant_colors, style_tags, object_tags,
                       1 - (caption_embedding <=> $1::vector(1024)) AS similarity
                FROM {ACTIVE_TABLE}
                WHERE status = 'active'
                  AND user_id = $2
                  AND caption_embedding IS NOT NULL
                  AND (1 - (caption_embedding <=> $1::vector(1024))) >= $3
                ORDER BY caption_embedding <=> $1::vector(1024)
                LIMIT $4;
            """, query_vec, normalized_user, threshold, top_k)
            
            results = []
            for row in rows:
                item = _row_to_dict(row)
                results.append(item)
            
            return results
    except Exception as e:
        print(f"[VectorDB] Error searching by caption embedding: {e}")
        import traceback
        traceback.print_exc()
        return []


async def batch_upsert_items(items: List[Dict], user_id: Optional[str], batch_size: int = 20) -> int:
    """
    æ‰¹é‡æ’å…¥æˆ–æ›´æ–° OpenGraph æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨å¹¶å‘å’Œæ‰¹é‡å¤„ç†ï¼‰
    
    âœ… åœ¨ä¿å­˜å‰è‡ªåŠ¨è¿‡æ»¤ï¼š
    1. æ–‡æ¡£ç±»å†…å®¹ï¼ˆä½¿ç”¨ is_doc_like è¿‡æ»¤ï¼‰
    2. é‡å¤çš„ captionï¼ˆå¦‚æœæ•°æ®åº“ä¸­å·²æœ‰ç›¸åŒçš„ captionï¼Œè·³è¿‡ï¼‰
    3. é‡å¤çš„ imageï¼ˆå¦‚æœæ•°æ®åº“ä¸­å·²æœ‰ç›¸åŒçš„ imageï¼Œè·³è¿‡ï¼‰
    
    Args:
        items: OpenGraph æ•°æ®åˆ—è¡¨ï¼ˆæ¯ä¸ªåŒ…å« url, title, description ç­‰å­—æ®µï¼‰
        user_id: ç”¨æˆ· ID
        batch_size: æ‰¹é‡å¤§å°ï¼ˆé»˜è®¤ 20ï¼Œæ§åˆ¶å¹¶å‘æ•°ï¼‰
    
    Returns:
        æˆåŠŸæ’å…¥/æ›´æ–°çš„æ•°é‡
    """
    if not items:
        return 0
    
    # âœ… è§„èŒƒåŒ–æ‰€æœ‰é¡¹
    from search.normalize import normalize_opengraph_items
    normalized_items = normalize_opengraph_items(items)
    
    # âœ… æ­¥éª¤ 1: è¿‡æ»¤æ–‡æ¡£ç±»å†…å®¹ï¼ˆä»æºå¤´é˜»æ­¢ï¼‰
    from search.preprocess import is_doc_like
    filtered_items = []
    doc_filtered_count = 0
    
    for item in normalized_items:
        if is_doc_like(item):
            doc_filtered_count += 1
            url = item.get("url", "N/A")
            title = item.get("title", "N/A")
            print(f"[VectorDB] ğŸš« è¿‡æ»¤æ–‡æ¡£ç±»å†…å®¹: {url[:60]}... (æ ‡é¢˜: {title[:40]}...)")
            continue
        filtered_items.append(item)
    
    if doc_filtered_count > 0:
        print(f"[VectorDB] ğŸ“Š æ–‡æ¡£ç±»å†…å®¹è¿‡æ»¤: {doc_filtered_count} é¡¹è¢«è¿‡æ»¤ï¼Œå‰©ä½™ {len(filtered_items)} é¡¹")
    
    if not filtered_items:
        print(f"[VectorDB] âš ï¸  æ‰€æœ‰é¡¹éƒ½è¢«è¿‡æ»¤ï¼Œæ²¡æœ‰å¯ä¿å­˜çš„æ•°æ®")
        return 0
    
    # âœ… æ­¥éª¤ 2: æ£€æŸ¥é‡å¤çš„ caption å’Œ imageï¼ˆæ‰¹é‡æŸ¥è¯¢ä¸€æ¬¡æ•°æ®åº“ï¼‰
    pool = await get_pool()
    duplicate_caption_count = 0
    duplicate_image_count = 0
    final_items = []
    
    try:
        async with pool.acquire() as conn:
            # æ”¶é›†æ‰€æœ‰éœ€è¦æ£€æŸ¥çš„ caption å’Œ image
            caption_map = {}  # normalized_caption -> List[item]
            image_map = {}    # image -> List[item]
            
            for item in filtered_items:
                # æ”¶é›† caption
                caption = item.get("image_caption") or (item.get("metadata") or {}).get("caption")
                if caption:
                    normalized_caption = caption.strip().lower()
                    if normalized_caption not in caption_map:
                        caption_map[normalized_caption] = []
                    caption_map[normalized_caption].append(item)
                
                # æ”¶é›† image
                image = item.get("image")
                if image:
                    if image not in image_map:
                        image_map[image] = []
                    image_map[image].append(item)
            
            # æ‰¹é‡æŸ¥è¯¢æ•°æ®åº“ä¸­å·²æœ‰çš„ caption
            existing_caption_set = set()
            if caption_map:
                caption_values = list(caption_map.keys())
                caption_query = f"""
                    SELECT DISTINCT LOWER(TRIM(COALESCE(image_caption, metadata->>'caption', ''))) as normalized_caption
                    FROM {ACTIVE_TABLE}
                    WHERE status = 'active'
                      AND user_id = $1
                      AND (
                        LOWER(TRIM(COALESCE(image_caption, ''))) = ANY($2::text[])
                        OR LOWER(TRIM(COALESCE(metadata->>'caption', ''))) = ANY($2::text[])
                      )
                """
                existing_captions = await conn.fetch(caption_query, user_id, caption_values)
                existing_caption_set = {row['normalized_caption'] for row in existing_captions if row['normalized_caption']}
            
            # æ‰¹é‡æŸ¥è¯¢æ•°æ®åº“ä¸­å·²æœ‰çš„ image
            existing_image_set = set()
            if image_map:
                image_values = list(image_map.keys())
                image_query = f"""
                    SELECT DISTINCT image
                    FROM {ACTIVE_TABLE}
                    WHERE status = 'active'
                      AND user_id = $1
                      AND image = ANY($2::text[])
                """
                existing_images = await conn.fetch(image_query, user_id, image_values)
                existing_image_set = {row['image'] for row in existing_images if row['image']}
            
            # å¯¹æ¯ä¸ªé¡¹ï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥è¢«è¿‡æ»¤ï¼ˆcaption æˆ– image é‡å¤ï¼‰
            items_to_skip = set()  # å­˜å‚¨è¦è·³è¿‡çš„ URL
            
            # æ£€æŸ¥ caption é‡å¤
            for normalized_caption, items in caption_map.items():
                if normalized_caption in existing_caption_set:
                    duplicate_caption_count += len(items)
                    for item in items:
                        url = item.get("url", "")
                        if url:
                            items_to_skip.add(url)
                            print(f"[VectorDB] ğŸš« è¿‡æ»¤é‡å¤ Caption: {url[:60]}... (Caption: {normalized_caption[:40]}...)")
            
            # æ£€æŸ¥ image é‡å¤
            for image, items in image_map.items():
                if image in existing_image_set:
                    for item in items:
                        url = item.get("url", "")
                        if url and url not in items_to_skip:
                            items_to_skip.add(url)
                            duplicate_image_count += 1
                            print(f"[VectorDB] ğŸš« è¿‡æ»¤é‡å¤ Image: {url[:60]}...")
            
            # æ„å»ºæœ€ç»ˆåˆ—è¡¨ï¼ˆæ’é™¤è¢«è¿‡æ»¤çš„é¡¹ï¼‰
            for item in filtered_items:
                url = item.get("url", "")
                if url not in items_to_skip:
                    final_items.append(item)
    
    except Exception as e:
        print(f"[VectorDB] âš ï¸  æ£€æŸ¥é‡å¤é¡¹æ—¶å‡ºé”™ï¼Œç»§ç»­ä¿å­˜æ‰€æœ‰è¿‡æ»¤åçš„é¡¹: {e}")
        import traceback
        traceback.print_exc()
        final_items = filtered_items
    
    if duplicate_caption_count > 0 or duplicate_image_count > 0:
        print(f"[VectorDB] ğŸ“Š é‡å¤é¡¹è¿‡æ»¤: Caption={duplicate_caption_count}, Image={duplicate_image_count}, å‰©ä½™ {len(final_items)} é¡¹")
    
    if not final_items:
        print(f"[VectorDB] âš ï¸  æ‰€æœ‰é¡¹éƒ½è¢«è¿‡æ»¤ï¼ˆæ–‡æ¡£ç±»æˆ–é‡å¤ï¼‰ï¼Œæ²¡æœ‰å¯ä¿å­˜çš„æ•°æ®")
        return 0
    
    # âœ… æ­¥éª¤ 3: è‡ªåŠ¨è¡¥é½ Caption å’Œè§†è§‰å±æ€§æ ‡ç­¾ï¼ˆåªå¯¹ç¼ºå¤±çš„é¡¹ï¼‰
    items_to_enrich = []
    items_already_have_caption = []
    
    for item in final_items:
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ caption å’Œæ ‡ç­¾
        has_caption = bool(item.get("image_caption") or (item.get("metadata") or {}).get("caption"))
        has_colors = bool(item.get("dominant_colors") and len(item.get("dominant_colors", [])) > 0)
        has_tags = bool(
            (item.get("style_tags") and len(item.get("style_tags", [])) > 0) or
            (item.get("object_tags") and len(item.get("object_tags", [])) > 0)
        )
        has_image = bool(item.get("image"))
        
        # å¦‚æœå·²æœ‰å®Œæ•´çš„ caption å’Œæ ‡ç­¾ï¼Œè·³è¿‡
        if has_caption and has_colors and has_tags:
            items_already_have_caption.append(item)
            continue
        
        # å¦‚æœæœ‰ image ä½†ç¼ºå°‘ caption æˆ–æ ‡ç­¾ï¼Œéœ€è¦è¡¥é½
        if has_image:
            items_to_enrich.append(item)
        else:
            # æ²¡æœ‰ imageï¼Œæ— æ³•ç”Ÿæˆ captionï¼Œç›´æ¥ä¿å­˜
            items_already_have_caption.append(item)
    
    # æ‰¹é‡ç”Ÿæˆ caption å’Œæ ‡ç­¾ï¼ˆåªå¯¹æœ‰ image ä¸”ç¼ºå¤±çš„é¡¹ï¼‰
    enriched_items = []
    if items_to_enrich:
        print(f"[VectorDB] ğŸ” è‡ªåŠ¨è¡¥é½ Caption å’Œæ ‡ç­¾: {len(items_to_enrich)} é¡¹éœ€è¦è¡¥é½")
        try:
            from search.caption import batch_enrich_items
            enriched_items = await batch_enrich_items(
                items_to_enrich,
                use_kmeans_colors=True,
                concurrent=min(5, len(items_to_enrich)),  # é™åˆ¶å¹¶å‘æ•°ï¼Œé¿å… API é™æµ
            )
            print(f"[VectorDB] âœ… æˆåŠŸè¡¥é½ {len(enriched_items)} é¡¹çš„ Caption å’Œæ ‡ç­¾")
            
            # å°†ç”Ÿæˆçš„å­—æ®µæ˜ å°„åˆ°æ­£ç¡®çš„å­—æ®µåï¼ˆenrich_item_with_caption è¿”å›çš„æ˜¯ "caption"ï¼Œéœ€è¦æ˜ å°„åˆ° "image_caption"ï¼‰
            for enriched_item in enriched_items:
                # enrich_item_with_caption è¿”å› "caption"ï¼Œéœ€è¦æ˜ å°„åˆ° "image_caption"
                if "caption" in enriched_item:
                    if "image_caption" not in enriched_item or not enriched_item.get("image_caption"):
                        enriched_item["image_caption"] = enriched_item.get("caption", "")
        except Exception as e:
            print(f"[VectorDB] âš ï¸  ç”Ÿæˆ Caption å’Œæ ‡ç­¾æ—¶å‡ºé”™ï¼Œç»§ç»­ä¿å­˜å…¶ä»–å­—æ®µ: {e}")
            import traceback
            traceback.print_exc()
            # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œä»ç„¶ä¿å­˜åŸå§‹é¡¹
            enriched_items = items_to_enrich
    
    # åˆå¹¶ï¼šå·²æœ‰å®Œæ•´å­—æ®µçš„é¡¹ + æ–°è¡¥é½çš„é¡¹
    all_items_to_save = items_already_have_caption + enriched_items
    
    if len(items_to_enrich) > 0:
        print(f"[VectorDB] ğŸ“Š å­—æ®µè¡¥é½ç»Ÿè®¡: å·²æœ‰å®Œæ•´å­—æ®µ={len(items_already_have_caption)}, æ–°è¡¥é½={len(enriched_items)}, æ€»è®¡={len(all_items_to_save)}")
    
    # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(batch_size)
    
    async def upsert_one(item: Dict) -> bool:
        async with semaphore:
            return await upsert_opengraph_item(
                user_id=user_id,
                url=item.get("url"),
                title=item.get("title"),
                description=item.get("description"),
                image=item.get("image"),
                site_name=item.get("site_name"),
                tab_id=item.get("tab_id"),
                tab_title=item.get("tab_title"),
                text_embedding=item.get("text_embedding"),
                image_embedding=item.get("image_embedding"),
                metadata=item.get("metadata"),
                # Caption ç›¸å…³å­—æ®µï¼ˆå¦‚æœæä¾›ï¼‰
                image_caption=item.get("image_caption"),
                caption_embedding=item.get("caption_embedding"),
                dominant_colors=item.get("dominant_colors"),
                style_tags=item.get("style_tags"),
                object_tags=item.get("object_tags"),
            )
    
    # å¹¶å‘å¤„ç†æ‰€æœ‰é¡¹ï¼ˆä½¿ç”¨è¡¥é½åçš„é¡¹ï¼‰
    tasks = [upsert_one(item) for item in all_items_to_save]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # ç»Ÿè®¡æˆåŠŸæ•°é‡
    success_count = sum(1 for r in results if r is True)
    
    return success_count


class VectorDBClient:
    """
    ç®€å•çš„æ•°æ®åº“å®¢æˆ·ç«¯ï¼Œå°è£…ç”¨æˆ·éš”ç¦»ç›¸å…³æ“ä½œ
    """
    def __init__(self, table_name: str = ACTIVE_TABLE_NAME):
        self.table_name = table_name
        self.qualified_table = _qualified(table_name)
    
    async def execute_query(self, query: str, params: Tuple = None, *, fetch: bool = False):
        pool = await get_pool()
        async with pool.acquire() as conn:
            if fetch:
                return await conn.fetch(query, *(params or ()))
            return await conn.execute(query, *(params or ()))
    
    async def upsert_item(self, item: Dict, user_id: str):
        """
        âœ… è‡ªåŠ¨å»é‡ï¼šä½¿ç”¨æ ‡å‡†åŒ– URLï¼ˆç§»é™¤æŸ¥è¯¢å‚æ•°ã€é”šç‚¹ï¼‰ä½œä¸ºå”¯ä¸€æ ‡è¯†
        """
        metadata_json = json.dumps(item.get("metadata") or {})
        text_vec = to_vector_str(item.get("text_embedding"))
        image_vec = to_vector_str(item.get("image_embedding"))
        # âœ… æ ‡å‡†åŒ– URL ç”¨äºå»é‡
        original_url = item.get("url")
        normalized_url = _normalize_url_for_storage(original_url) if original_url else None
        await self.execute_query(
            f"""
            INSERT INTO {self.qualified_table} (
                user_id, url, title, description, image, site_name,
                tab_id, tab_title, text_embedding, image_embedding, metadata, updated_at
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9::vector(1024), $10::vector(1024), $11::jsonb, NOW())
            ON CONFLICT (user_id, url) DO UPDATE SET
                title = EXCLUDED.title,
                description = EXCLUDED.description,
                image = EXCLUDED.image,
                site_name = EXCLUDED.site_name,
                tab_id = EXCLUDED.tab_id,
                tab_title = EXCLUDED.tab_title,
                text_embedding = EXCLUDED.text_embedding,
                image_embedding = EXCLUDED.image_embedding,
                metadata = EXCLUDED.metadata,
                updated_at = NOW();
            """,
            (
                _normalize_user_id(user_id),
                normalized_url,  # âœ… ä½¿ç”¨æ ‡å‡†åŒ– URL
                item.get("title"),
                item.get("description"),
                item.get("image"),
                item.get("site_name"),
                item.get("tab_id"),
                item.get("tab_title"),
                text_vec,
                image_vec,
                metadata_json,
            )
        )
    
    async def search_by_vector(
        self,
        query_vec: List[float],
        user_id: str,
        top_k: int = 20,
        min_similarity: float = 0.3
    ) -> List[Dict]:
        user_id = _normalize_user_id(user_id)
        vec_str = to_vector_str(query_vec)
        params = (vec_str, user_id, vec_str, min_similarity, vec_str, top_k)
        
        text_query = f"""
            SELECT *, 1 - (text_embedding <=> $1::vector(1024)) as text_similarity
            FROM {self.qualified_table}
            WHERE user_id = $2
              AND text_embedding IS NOT NULL
              AND 1 - (text_embedding <=> $3::vector(1024)) > $4
            ORDER BY text_embedding <=> $5::vector(1024)
            LIMIT $6
        """
        
        image_query = f"""
            SELECT *, 1 - (image_embedding <=> $1::vector(1024)) as image_similarity
            FROM {self.qualified_table}
            WHERE user_id = $2
              AND image_embedding IS NOT NULL
              AND 1 - (image_embedding <=> $3::vector(1024)) > $4
            ORDER BY image_embedding <=> $5::vector(1024)
            LIMIT $6
        """
        
        text_results = await self.execute_query(text_query, params, fetch=True)
        image_results = await self.execute_query(image_query, params, fetch=True)
        
        from search.rank import _choose_weights
        from search.fuse import fuse_similarity_scores
        
        combined: Dict[str, Dict] = {}
        
        for row in text_results:
            item = _row_to_dict(row)
            url = item["url"]
            combined[url] = item
            combined[url]["text_sim"] = float(row.get("text_similarity") or 0.0)
            combined[url]["image_sim"] = 0.0
        
        for row in image_results:
            item = _row_to_dict(row)
            url = item["url"]
            if url in combined:
                combined[url]["image_sim"] = float(row.get("image_similarity") or 0.0)
            else:
                item["text_sim"] = 0.0
                item["image_sim"] = float(row.get("image_similarity") or 0.0)
                combined[url] = item
        
        results = []
        for item in combined.values():
            weights = _choose_weights(item)
            similarity = fuse_similarity_scores(
                text_sim=item.get("text_sim", 0.0),
                image_sim=item.get("image_sim", 0.0),
                weights=weights,
                has_text=item.get("text_embedding") is not None,
                has_image=item.get("image_embedding") is not None
            )
            item["similarity"] = similarity
            results.append(item)
        
        results.sort(key=lambda x: x.get("similarity", 0.0), reverse=True)
        return results[:top_k]


async def soft_delete_tab(user_id: Optional[str], url: str) -> bool:
    """
    è½¯åˆ é™¤ä¸€ä¸ª tabï¼ˆOpenGraph itemï¼‰
    
    Args:
        user_id: ç”¨æˆ·ID
        url: ç½‘é¡µ URL
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        user_id = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            result = await conn.execute(f"""
                UPDATE {ACTIVE_TABLE}
                SET status = 'deleted',
                    deleted_at = NOW(),
                    updated_at = NOW()
                WHERE user_id = $1 AND url = $2 AND status = 'active';
            """, user_id, url)
            
            return result == "UPDATE 1"
    except Exception as e:
        print(f"[VectorDB] Error soft deleting tab {url[:50]}...: {e}")
        import traceback
        traceback.print_exc()
        return False


async def soft_delete_session_tabs(user_id: Optional[str], session_id: str) -> int:
    """
    è½¯åˆ é™¤ä¸€ä¸ª session ä¸‹çš„æ‰€æœ‰ tabs
    
    Args:
        user_id: ç”¨æˆ·ID
        session_id: Session IDï¼ˆå­˜å‚¨åœ¨ metadata ä¸­ï¼‰
    
    Returns:
        åˆ é™¤çš„ tab æ•°é‡
    """
    try:
        user_id = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            # æŸ¥æ‰¾è¯¥ session çš„æ‰€æœ‰ tabsï¼ˆé€šè¿‡ metadata ä¸­çš„ session_idï¼‰
            result = await conn.execute(f"""
                UPDATE {ACTIVE_TABLE}
                SET status = 'deleted',
                    deleted_at = NOW(),
                    updated_at = NOW()
                WHERE user_id = $1 
                  AND status = 'active'
                  AND metadata->>'session_id' = $2;
            """, user_id, session_id)
            
            # è§£æ UPDATE ç»“æœè·å–å½±å“è¡Œæ•°
            if result.startswith("UPDATE "):
                count = int(result.split()[1])
                return count
            return 0
    except Exception as e:
        print(f"[VectorDB] Error soft deleting session {session_id}: {e}")
        import traceback
        traceback.print_exc()
        return 0


async def get_user_active_tabs(user_id: Optional[str]) -> List[Dict]:
    """
    è·å–ç”¨æˆ·çš„æ‰€æœ‰ active tabs
    
    Args:
        user_id: ç”¨æˆ·ID
    
    Returns:
        OpenGraph æ•°æ®åˆ—è¡¨
    """
    try:
        user_id = _normalize_user_id(user_id)
        pool = await get_pool()
        
        async with pool.acquire() as conn:
            rows = await conn.fetch(f"""
                SELECT user_id, url, title, description, image, screenshot_image, site_name,
                       tab_id, tab_title, text_embedding, image_embedding, metadata
                FROM {ACTIVE_TABLE}
                WHERE user_id = $1 AND status = 'active'
                ORDER BY created_at DESC;
            """, user_id)
            
            return [_row_to_dict(row) for row in rows]
    except Exception as e:
        print(f"[VectorDB] Error getting user active tabs: {e}")
        import traceback
        traceback.print_exc()
        return []

