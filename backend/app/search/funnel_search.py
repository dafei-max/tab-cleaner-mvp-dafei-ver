"""
ä¸‰é˜¶æ®µæ¼æ–—æœç´¢æ¨¡å—
1. ç²—å¬å›ï¼ˆMulti-Recallï¼‰ï¼šå¤šè·¯å¾„å¬å› 100-200 ä¸ªå€™é€‰
2. ç²¾æ’åºï¼ˆRe-Rankingï¼‰ï¼šèåˆ 5 è·¯åˆ†æ•°
3. åŠ¨æ€è¿‡æ»¤ï¼ˆThreshold Filteringï¼‰ï¼šæ ¹æ®è´¨é‡åŠ¨æ€è¿”å› 1-20 ä¸ªç»“æœ
"""
from typing import List, Dict, Optional, Tuple
import asyncio
from .threshold_filter import FilterMode, filter_by_threshold
from .smart_filter import smart_filter
from .embed import embed_text, embed_image
from .fuse import cosine_similarity, fuse_similarity_scores
from .rank import fuzzy_score
from .query_enhance import enhance_visual_query
import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from vector_db import (
    search_by_text_embedding,
    search_by_image_embedding,
    get_pool,
    ACTIVE_TABLE,
    NAMESPACE,
    _normalize_user_id,
)
import asyncpg


# äº”è·¯åˆ†æ•°æƒé‡é…ç½®ï¼ˆä» fusion_weights æ¨¡å—å¯¼å…¥ï¼Œå¯é…ç½®ï¼‰
from .fusion_weights import FUSION_WEIGHTS


async def _coarse_recall_text_vector(
    user_id: Optional[str],
    query_text: str,
    top_k: int = 50,
) -> List[Dict]:
    """
    è·¯å¾„1: æ–‡æœ¬å‘é‡æœç´¢
    
    Args:
        user_id: ç”¨æˆ·ID
        query_text: æŸ¥è¯¢æ–‡æœ¬
        top_k: å¬å›æ•°é‡
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨ï¼ˆåŒ…å« similarity å­—æ®µï¼‰
    """
    try:
        from .embed import embed_text
        query_vec = await embed_text(query_text)
        if not query_vec:
            return []
        
        results = await search_by_text_embedding(
            user_id=user_id,
            query_embedding=query_vec,
            top_k=top_k,
            threshold=0.0,  # é™ä½é˜ˆå€¼ï¼šå…è®¸æ›´å¤šå€™é€‰ç»“æœè¿›å…¥ç²¾æ’åºé˜¶æ®µ
        )
        
        # æ·»åŠ è·¯å¾„æ ‡è¯†
        for item in results:
            item["recall_path"] = "text_vector"
            item["text_similarity"] = item.get("similarity", 0.0)
        
        print(f"[Funnel] Text vector recall: found {len(results)} results for user_id={user_id}")
        return results
    except Exception as e:
        print(f"[Funnel] Error in text vector recall: {e}")
        import traceback
        traceback.print_exc()
        return []


async def _coarse_recall_image_vector(
    user_id: Optional[str],
    query_image_url: Optional[str] = None,
    query_image_base64: Optional[str] = None,
    top_k: int = 50,
) -> List[Dict]:
    """
    è·¯å¾„2: å›¾åƒå‘é‡æœç´¢
    
    Args:
        user_id: ç”¨æˆ·ID
        query_image_url: æŸ¥è¯¢å›¾åƒURL
        query_image_base64: æŸ¥è¯¢å›¾åƒBase64
        top_k: å¬å›æ•°é‡
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨ï¼ˆåŒ…å« similarity å­—æ®µï¼‰
    """
    try:
        from .embed import embed_image
        query_vec = await embed_image(query_image_url, query_image_base64)
        if not query_vec:
            return []
        
        results = await search_by_image_embedding(
            user_id=user_id,
            query_embedding=query_vec,
            top_k=top_k,
            threshold=0.0,  # é™ä½é˜ˆå€¼ï¼šå…è®¸æ›´å¤šå€™é€‰ç»“æœè¿›å…¥ç²¾æ’åºé˜¶æ®µ
        )
        
        # æ·»åŠ è·¯å¾„æ ‡è¯†
        for item in results:
            item["recall_path"] = "image_vector"
            item["image_similarity"] = item.get("similarity", 0.0)
        
        return results
    except Exception as e:
        print(f"[Funnel] Error in image vector recall: {e}")
        return []


async def _coarse_recall_caption_keyword(
    user_id: Optional[str],
    query_text: str,
    top_k: int = 50,
) -> List[Dict]:
    """
    è·¯å¾„3: Caption å…³é”®è¯æœç´¢ï¼ˆå…¨æ–‡æœç´¢ï¼‰
    
    Args:
        user_id: ç”¨æˆ·ID
        query_text: æŸ¥è¯¢æ–‡æœ¬
        top_k: å¬å›æ•°é‡
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    try:
        pool = await get_pool()
        normalized_user = _normalize_user_id(user_id)
        
        # ä½¿ç”¨ PostgreSQL å…¨æ–‡æœç´¢
        # å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸º tsquery
        query_tokens = query_text.lower().split()
        tsquery = " & ".join(query_tokens)  # AND æŸ¥è¯¢
        
        async with pool.acquire() as conn:
            # æ£€æŸ¥æ˜¯å¦æœ‰ image_caption å­—æ®µ
            has_caption_field = await conn.fetchval(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.columns 
                    WHERE table_schema = '{NAMESPACE}'
                      AND table_name = 'opengraph_items_v2'
                      AND column_name = 'image_caption'
                );
            """)
            
            if not has_caption_field:
                # é™çº§åˆ° metadata æŸ¥è¯¢
                rows = await conn.fetch(f"""
                    SELECT user_id, url, title, description, image, site_name,
                           tab_id, tab_title, metadata,
                           ts_rank(to_tsvector('english', COALESCE(metadata->>'caption', '')), 
                                   plainto_tsquery('english', $1)) AS rank
                    FROM {ACTIVE_TABLE}
                    WHERE status = 'active'
                      AND user_id = $2
                      AND metadata ? 'caption'
                      AND metadata->>'caption' IS NOT NULL
                      AND metadata->>'caption' != ''
                      AND to_tsvector('english', metadata->>'caption') @@ plainto_tsquery('english', $1)
                    ORDER BY rank DESC
                    LIMIT $3;
                """, query_text, normalized_user, top_k)
            else:
                rows = await conn.fetch(f"""
                    SELECT user_id, url, title, description, image, site_name,
                           tab_id, tab_title, metadata,
                           image_caption, caption_embedding, dominant_colors, style_tags, object_tags,
                           ts_rank(to_tsvector('english', COALESCE(image_caption, '')), 
                                   plainto_tsquery('english', $1)) AS rank
                    FROM {ACTIVE_TABLE}
                    WHERE status = 'active'
                      AND user_id = $2
                      AND image_caption IS NOT NULL
                      AND image_caption != ''
                      AND to_tsvector('english', image_caption) @@ plainto_tsquery('english', $1)
                    ORDER BY rank DESC
                    LIMIT $3;
                """, query_text, normalized_user, top_k)
            
            results = []
            for row in rows:
                item = dict(row)
                # å½’ä¸€åŒ– rank åˆ° [0, 1]ï¼ˆç¡®ä¿è½¬æ¢ä¸º floatï¼‰
                rank = item.get("rank", 0.0)
                item["caption_similarity"] = min(float(rank), 1.0)
                item["recall_path"] = "caption_keyword"
                results.append(item)
            
            print(f"[Funnel] Caption keyword recall: found {len(results)} results for user_id={user_id}")
            return results
    except Exception as e:
        print(f"[Funnel] Error in caption keyword recall: {e}")
        import traceback
        traceback.print_exc()
        return []


async def _coarse_recall_visual_attributes(
    user_id: Optional[str],
    query_text: str,
    top_k: int = 50,
) -> List[Dict]:
    """
    è·¯å¾„4: é¢œè‰²/é£æ ¼æ ‡ç­¾æœç´¢
    
    Args:
        user_id: ç”¨æˆ·ID
        query_text: æŸ¥è¯¢æ–‡æœ¬
        top_k: å¬å›æ•°é‡
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    try:
        # æå–è§†è§‰å±æ€§ï¼ˆé¢œè‰²ã€é£æ ¼ï¼‰
        visual_attrs = enhance_visual_query(query_text)
        colors = visual_attrs.get("colors", [])
        styles = visual_attrs.get("styles", [])
        
        if not colors and not styles:
            return []
        
        pool = await get_pool()
        normalized_user = _normalize_user_id(user_id)
        
        async with pool.acquire() as conn:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å­—æ®µ
            has_new_fields = await conn.fetchval(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.columns 
                    WHERE table_schema = '{NAMESPACE}'
                      AND table_name = 'opengraph_items_v2'
                      AND column_name = 'dominant_colors'
                );
            """)
            
            if not has_new_fields:
                return []
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            conditions = []
            params = [normalized_user]
            param_idx = 2
            
            if colors:
                # é¢œè‰²åŒ¹é…ï¼ˆä½¿ç”¨æ•°ç»„åŒ…å«æ“ä½œç¬¦ï¼‰
                color_conditions = []
                for color in colors:
                    color_conditions.append(f"${param_idx} = ANY(dominant_colors)")
                    params.append(color.lower())
                    param_idx += 1
                conditions.append(f"({' OR '.join(color_conditions)})")
            
            if styles:
                # é£æ ¼åŒ¹é…
                style_conditions = []
                for style in styles:
                    style_conditions.append(f"${param_idx} = ANY(style_tags)")
                    params.append(style.lower())
                    param_idx += 1
                conditions.append(f"({' OR '.join(style_conditions)})")
            
            if not conditions:
                return []
            
            where_clause = " AND ".join(conditions)
            params.append(top_k)
            
            query = f"""
                SELECT user_id, url, title, description, image, site_name,
                       tab_id, tab_title, metadata,
                       image_caption, caption_embedding, dominant_colors, style_tags, object_tags,
                       CASE 
                           WHEN dominant_colors && ARRAY[{','.join([f'${i+2}' for i, c in enumerate(colors)])}]::TEXT[] 
                                THEN 0.7
                           ELSE 0.0
                       END +
                       CASE 
                           WHEN style_tags && ARRAY[{','.join([f'${len(colors)+i+2}' for i, s in enumerate(styles)])}]::TEXT[] 
                                THEN 0.3
                           ELSE 0.0
                       END AS visual_score
                FROM {ACTIVE_TABLE}
                WHERE status = 'active'
                  AND user_id = $1
                  AND ({where_clause})
                ORDER BY visual_score DESC
                LIMIT ${param_idx};
            """
            
            rows = await conn.fetch(query, *params)
            
            results = []
            for row in rows:
                item = dict(row)
                # ç¡®ä¿è½¬æ¢ä¸º float
                visual_score = item.get("visual_score", 0.0)
                item["visual_attributes_score"] = float(visual_score) if visual_score is not None else 0.0
                item["recall_path"] = "visual_attributes"
                results.append(item)
            
            print(f"[Funnel] Visual attributes recall: found {len(results)} results for user_id={user_id}")
            return results
    except Exception as e:
        print(f"[Funnel] Error in visual attributes recall: {e}")
        import traceback
        traceback.print_exc()
        return []


async def _fine_ranking(
    candidates: List[Dict],
    query_text: str,
    query_text_vec: Optional[List[float]] = None,
    query_image_vec: Optional[List[float]] = None,
) -> List[Dict]:
    """
    ç²¾æ’åºï¼šèåˆ 5 è·¯åˆ†æ•°
    
    äº”è·¯åˆ†æ•°ï¼š
    1. æ–‡æœ¬ç›¸ä¼¼åº¦ (15%)
    2. å›¾åƒç›¸ä¼¼åº¦ (35%)
    3. Caption ç›¸ä¼¼åº¦ (20%)
    4. å…³é”®è¯åŒ¹é… (15%)
    5. è§†è§‰å±æ€§åŒ¹é… (15%)
    
    Args:
        candidates: å€™é€‰ç»“æœåˆ—è¡¨
        query_text: æŸ¥è¯¢æ–‡æœ¬
        query_text_vec: æŸ¥è¯¢æ–‡æœ¬å‘é‡ï¼ˆå¯é€‰ï¼Œå¦‚æœæœªæä¾›ä¼šè®¡ç®—ï¼‰
        query_image_vec: æŸ¥è¯¢å›¾åƒå‘é‡ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        æ’åºåçš„ç»“æœåˆ—è¡¨ï¼ˆåŒ…å« similarity å­—æ®µï¼‰
    """
    if not candidates:
        return []
    
    # å¦‚æœæœªæä¾›æ–‡æœ¬å‘é‡ï¼Œè®¡ç®—å®ƒ
    if query_text_vec is None and query_text:
        try:
            query_text_vec = await embed_text(query_text)
        except Exception as e:
            print(f"[Funnel] Error computing query text vector: {e}")
            query_text_vec = None
    
    # åˆå¹¶ç»“æœï¼ˆå»é‡ï¼‰
    merged = {}  # url -> item
    
    for item in candidates:
        url = item.get("url")
        if not url:
            continue
        
        if url not in merged:
            merged[url] = {
                "text_similarity": 0.0,
                "image_similarity": 0.0,
                "caption_similarity": 0.0,
                "keyword_score": 0.0,
                "visual_attributes_score": 0.0,
                "recall_paths": set(),
            }
            # å¤åˆ¶åŸå§‹å­—æ®µ
            for key, value in item.items():
                if key not in ["text_similarity", "image_similarity", "caption_similarity", 
                              "keyword_score", "visual_attributes_score", "similarity", 
                              "recall_path", "recall_paths"]:
                    merged[url][key] = value
        
        # åˆå¹¶åˆ†æ•°ï¼ˆç¡®ä¿è½¬æ¢ä¸º floatï¼‰
        merged[url]["text_similarity"] = max(
            merged[url]["text_similarity"],
            float(item.get("text_similarity", 0.0) or 0.0)
        )
        merged[url]["image_similarity"] = max(
            merged[url]["image_similarity"],
            float(item.get("image_similarity", 0.0) or 0.0)
        )
        merged[url]["caption_similarity"] = max(
            merged[url]["caption_similarity"],
            float(item.get("caption_similarity", 0.0) or 0.0)
        )
        merged[url]["visual_attributes_score"] = max(
            merged[url]["visual_attributes_score"],
            float(item.get("visual_attributes_score", 0.0) or 0.0)
        )
        merged[url]["recall_paths"].add(item.get("recall_path", "unknown"))
        
        # è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°
        title = item.get("title", "")
        description = item.get("description", "")
        # å¤„ç† metadataï¼ˆå¯èƒ½æ˜¯ dict æˆ– strï¼‰
        metadata = item.get("metadata", {})
        if isinstance(metadata, str):
            import json
            try:
                metadata = json.loads(metadata)
            except:
                metadata = {}
        caption = item.get("image_caption") or (metadata.get("caption", "") if isinstance(metadata, dict) else "")
        
        keyword_score = fuzzy_score(query_text, title, f"{description} {caption}")
        merged[url]["keyword_score"] = max(merged[url]["keyword_score"], float(keyword_score))
    
    # è®¡ç®—èåˆåˆ†æ•°
    results = []
    for url, item in merged.items():
        # å¦‚æœç¼ºå°‘å‘é‡ç›¸ä¼¼åº¦ï¼Œå°è¯•è®¡ç®—
        if query_text_vec and item.get("text_embedding") and item["text_similarity"] == 0.0:
            try:
                text_vec = item.get("text_embedding")
                if isinstance(text_vec, list):
                    item["text_similarity"] = max(
                        item["text_similarity"],
                        cosine_similarity(query_text_vec, text_vec)
                    )
            except Exception as e:
                print(f"[Funnel] Error computing text similarity for {url}: {e}")
        
        if query_image_vec and item.get("image_embedding") and item["image_similarity"] == 0.0:
            try:
                image_vec = item.get("image_embedding")
                if isinstance(image_vec, list):
                    item["image_similarity"] = max(
                        item["image_similarity"],
                        cosine_similarity(query_image_vec, image_vec)
                    )
            except Exception as e:
                print(f"[Funnel] Error computing image similarity for {url}: {e}")
        
        # èåˆäº”è·¯åˆ†æ•°
        weights = FUSION_WEIGHTS
        fused_score = (
            weights["text_similarity"] * item["text_similarity"] +
            weights["image_similarity"] * item["image_similarity"] +
            weights["caption_similarity"] * item["caption_similarity"] +
            weights["keyword_match"] * item["keyword_score"] +
            weights["visual_attributes"] * item["visual_attributes_score"]
        )
        
        item["similarity"] = fused_score
        item["recall_paths"] = list(item["recall_paths"])
        results.append(item)
    
    # æŒ‰èåˆåˆ†æ•°æ’åº
    results.sort(key=lambda x: x.get("similarity", 0.0), reverse=True)
    
    return results


async def search_with_funnel(
    user_id: Optional[str],
    query_text: str,
    query_image_url: Optional[str] = None,
    query_image_base64: Optional[str] = None,
    filter_mode: FilterMode = FilterMode.BALANCED,
    max_results: Optional[int] = None,  # æ”¹ä¸ºå¯é€‰ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶æ•°é‡ï¼Œåªæ ¹æ®è´¨é‡è¿‡æ»¤
    use_caption: bool = True,
) -> List[Dict]:
    """
    ä¸‰é˜¶æ®µæ¼æ–—æœç´¢
    
    Args:
        user_id: ç”¨æˆ·ID
        query_text: æŸ¥è¯¢æ–‡æœ¬
        query_image_url: æŸ¥è¯¢å›¾åƒURLï¼ˆå¯é€‰ï¼‰
        query_image_base64: æŸ¥è¯¢å›¾åƒBase64ï¼ˆå¯é€‰ï¼‰
        filter_mode: è¿‡æ»¤æ¨¡å¼
        max_results: æœ€å¤§è¿”å›æ•°é‡
        use_caption: æ˜¯å¦ä½¿ç”¨ Caption æœç´¢
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨ï¼ˆæ ¹æ®è´¨é‡é˜ˆå€¼åŠ¨æ€è¿”å›ï¼Œä¸é™åˆ¶æ•°é‡ï¼‰
    """
    print(f"[Funnel] Starting funnel search for query: {query_text[:50]}...")
    
    # ========== é˜¶æ®µ 1: ç²—å¬å›ï¼ˆMulti-Recallï¼‰ ==========
    print("[Funnel] Stage 1: Coarse Recall (Multi-Recall)")
    
    recall_tasks = []
    
    # è·¯å¾„1: æ–‡æœ¬å‘é‡æœç´¢
    recall_tasks.append(_coarse_recall_text_vector(user_id, query_text, top_k=50))
    
    # è·¯å¾„2: å›¾åƒå‘é‡æœç´¢ï¼ˆå¦‚æœæœ‰å›¾åƒï¼‰
    if query_image_url or query_image_base64:
        recall_tasks.append(_coarse_recall_image_vector(
            user_id, query_image_url, query_image_base64, top_k=50
        ))
    
    # è·¯å¾„3: Caption å…³é”®è¯æœç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if use_caption:
        recall_tasks.append(_coarse_recall_caption_keyword(user_id, query_text, top_k=50))
    
    # è·¯å¾„4: è§†è§‰å±æ€§æœç´¢
    recall_tasks.append(_coarse_recall_visual_attributes(user_id, query_text, top_k=50))
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å¬å›è·¯å¾„
    recall_results = await asyncio.gather(*recall_tasks, return_exceptions=True)
    
    # åˆå¹¶å¬å›ç»“æœ
    all_candidates = []
    for results in recall_results:
        if isinstance(results, Exception):
            print(f"[Funnel] Recall path error: {results}")
            continue
        all_candidates.extend(results)
    
    print(f"[Funnel] Coarse recall: {len(all_candidates)} candidates")
    
    if not all_candidates:
        print("[Funnel] âš ï¸  No candidates found in recall stage")
        print("[Funnel] ğŸ’¡  Possible reasons:")
        print("[Funnel]    1. No data in database for this user")
        print("[Funnel]    2. No embeddings generated")
        print("[Funnel]    3. User ID mismatch")
        print("[Funnel]    4. Query embedding generation failed")
        return []
    
    # ========== é˜¶æ®µ 2: ç²¾æ’åºï¼ˆRe-Rankingï¼‰ ==========
    print("[Funnel] Stage 2: Fine Ranking (Re-Ranking)")
    
    # è®¡ç®—æŸ¥è¯¢å‘é‡ï¼ˆç”¨äºç²¾æ’åºï¼‰
    query_text_vec = None
    query_image_vec = None
    
    if query_text:
        try:
            query_text_vec = await embed_text(query_text)
        except Exception as e:
            print(f"[Funnel] Error computing query text vector: {e}")
    
    if query_image_url or query_image_base64:
        try:
            query_image_vec = await embed_image(query_image_url, query_image_base64)
        except Exception as e:
            print(f"[Funnel] Error computing query image vector: {e}")
    
    ranked_results = await _fine_ranking(
        all_candidates,
        query_text,
        query_text_vec,
        query_image_vec,
    )
    
    print(f"[Funnel] Fine ranking: {len(ranked_results)} ranked results")
    
    # ========== é˜¶æ®µ 3: AIç›‘ç£ç­›é€‰ï¼ˆSmart Filteringï¼‰ ==========
    print(f"[Funnel] Stage 3: AI-Supervised Smart Filtering (mode={filter_mode.value})")
    
    # ä½¿ç”¨AIç›‘ç£ç­›é€‰ï¼šæ ¹æ®æŸ¥è¯¢ç±»å‹æ™ºèƒ½è°ƒæ•´è¿‡æ»¤ç­–ç•¥
    # filter_docs=True: é’ˆå¯¹è®¾è®¡å¸ˆåœºæ™¯ï¼Œè‡ªåŠ¨è¿‡æ»¤æ–‡æ¡£ç±»å†…å®¹
    filtered_results = smart_filter(
        ranked_results,
        query_text,
        filter_mode=filter_mode,
        max_results=max_results,
        filter_docs=True,  # è®¾è®¡å¸ˆåœºæ™¯ï¼šè¿‡æ»¤æ–‡æ¡£ç±»å†…å®¹
    )
    
    print(f"[Funnel] Final results: {len(filtered_results)} items")
    
    return filtered_results

