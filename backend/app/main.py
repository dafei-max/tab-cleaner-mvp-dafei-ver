from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pathlib import Path
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from datetime import datetime
import json
import os
# âœ… å·²ç§»é™¤ï¼šä¸å†ä»åç«¯æŠ“å– OpenGraphï¼Œåªæ¥æ”¶å®¢æˆ·ç«¯æ•°æ®
# from opengraph import fetch_multiple_opengraph
from ai_insight import analyze_opengraph_data
from search import process_opengraph_for_search
from clustering import create_manual_cluster, classify_by_labels, discover_clusters
from clustering.storage import save_clustering_result, save_multiple_clusters

app = FastAPI(title="Tab Cleaner MVP", version="0.0.1")


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
    try:
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†æ•°æ®åº“è¿æ¥
        db_host = os.getenv("ADBPG_HOST", "")
        if db_host:
            try:
                from vector_db import init_schema
                print("[Startup] Initializing vector database...")
                await init_schema()
                print("[Startup] âœ“ Vector database initialized successfully")
            except ImportError as import_error:
                print(f"[Startup] âš  Vector DB module import failed: {import_error}")
                print("[Startup] âš  This is expected if asyncpg is not installed. Vector DB features will be disabled.")
                print("[Startup] âš  To enable vector DB, ensure asyncpg is installed: pip install asyncpg>=0.30.0")
            except Exception as db_error:
                print(f"[Startup] âš  Vector DB initialization failed: {db_error}")
                print("[Startup] âš  Continuing without vector database...")
                import traceback
                traceback.print_exc()
        else:
            print("[Startup] ADBPG_HOST not configured, skipping vector database initialization")
    except Exception as e:
        print(f"[Startup] âš  Startup event error (non-critical): {e}")
        # ä¸é˜»æ­¢åº”ç”¨å¯åŠ¨


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶æ¸…ç†èµ„æº"""
    try:
        from vector_db import close_pool
        await close_pool()
        print("[Shutdown] Vector database connection pool closed")
    except Exception as e:
        print(f"[Shutdown] Error closing vector database: {e}")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# serve static pages (for share link)
# æ³¨æ„ï¼šå¦‚æœä¸éœ€è¦é™æ€æ–‡ä»¶æœåŠ¡ï¼Œå¯ä»¥åˆ é™¤ static ç›®å½•
static_dir = Path(__file__).parent / "static"
# åªæœ‰å½“ static ç›®å½•å­˜åœ¨ä¸”ä¸ä¸ºç©ºæ—¶æ‰æŒ‚è½½
if static_dir.exists() and static_dir.is_dir():
    try:
        app.mount("/public", StaticFiles(directory=static_dir, html=True), name="public")
    except Exception as e:
        # å¦‚æœæŒ‚è½½å¤±è´¥ï¼ˆä¾‹å¦‚ç›®å½•ä¸ºç©ºï¼‰ï¼Œè®°å½•è­¦å‘Šä½†ä¸å½±å“åº”ç”¨å¯åŠ¨
        print(f"[Warning] Failed to mount static directory: {e}")

@app.get("/")
def root():
    return {"ok": True, "message": "Hello Tab Cleaner"}


@app.get("/favicon.ico")
async def favicon():
    """è¿”å› favicon å›¾æ ‡"""
    # ä¼˜å…ˆå°è¯• .ico æ ¼å¼
    favicon_path = Path(__file__).parent / "static" / "favicon.ico"
    if not favicon_path.exists():
        # å¦‚æœæ²¡æœ‰ .icoï¼Œå°è¯• .png
        favicon_path = Path(__file__).parent / "static" / "favicon.png"
    
    if favicon_path.exists():
        return FileResponse(favicon_path)
    # å¦‚æœæ²¡æœ‰ faviconï¼Œè¿”å› 204 No Content
    from fastapi.responses import Response
    return Response(status_code=204)


# OpenGraph API
class TabItem(BaseModel):
    url: str
    title: Optional[str] = None
    id: Optional[int] = None


class OpenGraphRequest(BaseModel):
    tabs: List[TabItem]
    # å¯é€‰ï¼šå‰ç«¯å·²æŠ“å–çš„ OpenGraph æ•°æ®ï¼ˆç”¨äºéœ€è¦ç™»å½•çš„ç½‘ç«™ï¼‰
    local_opengraph_data: Optional[List[Dict[str, Any]]] = None


@app.post("/api/v1/tabs/opengraph")
async def fetch_tabs_opengraph(request: OpenGraphRequest):
    """
    æ¥æ”¶å®¢æˆ·ç«¯å‘é€çš„æœ¬åœ° OpenGraph æ•°æ®
    åç«¯ä¸å†ä¸»åŠ¨æŠ“å– OpenGraphï¼Œåªæ¥æ”¶å’Œå¤„ç†å®¢æˆ·ç«¯æ•°æ®
    """
    try:
        print(f"[API] ğŸ“¥ /api/v1/tabs/opengraph endpoint called")
        print(f"[API] Request details: tabs={len(request.tabs)}, local_opengraph_data={len(request.local_opengraph_data) if request.local_opengraph_data else 0}")
        
        # âœ… ç®€åŒ–ï¼šåªæ¥æ”¶å®¢æˆ·ç«¯å‘é€çš„ local_opengraph_data
        if request.local_opengraph_data and len(request.local_opengraph_data) > 0:
            print(f"[API] âœ… Received local OpenGraph data for {len(request.local_opengraph_data)} items")
            
            # æ‰“å°ç¬¬ä¸€ä¸ª item çš„è¯¦ç»†ä¿¡æ¯
            if len(request.local_opengraph_data) > 0:
                first_item = request.local_opengraph_data[0]
                print(f"[API] ğŸ“‹ First local OG item sample:", {
                    "url": first_item.get("url"),
                    "has_title": bool(first_item.get("title")),
                    "has_description": bool(first_item.get("description")),
                    "has_image": bool(first_item.get("image")),
                    "image_preview": str(first_item.get("image"))[:60] + "..." if first_item.get("image") else None,
                    "success": first_item.get("success"),
                    "is_local_fetch": first_item.get("is_local_fetch"),
                })
            
            # åˆ›å»º tab URL åˆ° tab ä¿¡æ¯çš„æ˜ å°„
            tab_map = {tab.url: tab for tab in request.tabs}
            
            # å¤„ç†æœ¬åœ°æ•°æ®ï¼šæ ‡è®°ä¸º is_local_fetch=Trueï¼Œå¹¶åˆå¹¶ tab ä¿¡æ¯
            opengraph_data = []
            for item in request.local_opengraph_data:
                url = item.get("url")
                if not url:
                    continue
                
                tab = tab_map.get(url)
                normalized_item = {
                    **item,
                    "is_local_fetch": True,  # âœ… æ ‡è®°ä¸ºæœ¬åœ°æŠ“å–
                    "tab_id": tab.id if tab else None,
                    "tab_title": tab.title if tab else None,
                }
                opengraph_data.append(normalized_item)
            
            print(f"[API] âœ… Processed {len(opengraph_data)} items from local OpenGraph data")
            return {"ok": True, "data": opengraph_data}
        else:
            # âœ… å¦‚æœæ²¡æœ‰æœ¬åœ°æ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨å¹¶è®°å½•è­¦å‘Š
            print("[API] âš ï¸ No local_opengraph_data provided; backend no longer fetches OG by itself.")
            return {"ok": True, "data": []}
    except Exception as e:
        print(f"[API] âŒ Error processing OpenGraph request: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


# AI æ´å¯Ÿ API
class AIInsightRequest(BaseModel):
    opengraph_items: List[Dict[str, Any]]


@app.post("/api/v1/ai/insight")
async def get_ai_insight(request: AIInsightRequest):
    """
    ä½¿ç”¨é€šä¹‰åƒé—®åˆ†æ OpenGraph æ•°æ®å¹¶ç”Ÿæˆæ€»ç»“
    """
    try:
        if not request.opengraph_items:
            raise HTTPException(status_code=400, detail="No OpenGraph items provided")
        
        result = analyze_opengraph_data(request.opengraph_items)
        
        if result["success"]:
            return {
                "ok": True,
                "summary": result["summary"],
                "error": None
            }
        else:
            return {
                "ok": False,
                "summary": None,
                "error": result.get("error", "Unknown error")
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# æœç´¢ API
class EmbeddingRequest(BaseModel):
    opengraph_items: List[Dict[str, Any]]


class SearchRequest(BaseModel):
    query: str
    top_k: Optional[int] = 20


@app.post("/api/v1/search/embedding")
async def generate_embeddings(request: EmbeddingRequest):
    """
    ä¸ºOpenGraphæ•°æ®ç”ŸæˆEmbeddingå‘é‡å¹¶å­˜å‚¨åˆ°æ•°æ®åº“
    
    æµç¨‹ï¼š
    1. è°ƒç”¨ process_opengraph_for_search() ç”Ÿæˆ text_embedding å’Œ image_embedding
    2. è°ƒç”¨ batch_upsert_items() æ‰¹é‡å­˜å‚¨åˆ°æ•°æ®åº“
    3. è¿”å›åŒ…å« saved å­—æ®µçš„å“åº”
    """
    try:
        if not request.opengraph_items:
            print("[API] âš ï¸ No opengraph_items provided in request")
            return {"ok": True, "saved": 0, "data": []}
        
        print(f"[API] ğŸ“¥ Received request with {len(request.opengraph_items)} items for embedding generation")
        print(f"[API] ğŸ” Endpoint: /api/v1/search/embedding")
        
        # âœ… æ·»åŠ è¯¦ç»†æ—¥å¿—ï¼šæ‰“å°ç¬¬ä¸€ä¸ª item çš„å­—æ®µ
        if len(request.opengraph_items) > 0:
            first_item = request.opengraph_items[0]
            print(f"[API] ğŸ“‹ First item sample:", {
                "url": first_item.get("url"),
                "has_title": bool(first_item.get("title")),
                "has_description": bool(first_item.get("description")),
                "has_image": bool(first_item.get("image")),
                "image_type": type(first_item.get("image")).__name__ if first_item.get("image") else None,
                "image_preview": str(first_item.get("image"))[:60] + "..." if first_item.get("image") else None,
                "tab_id": first_item.get("tab_id"),
                "is_doc_card": first_item.get("is_doc_card"),
                "success": first_item.get("success"),
                "is_local_fetch": first_item.get("is_local_fetch"),  # âœ… æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°æŠ“å–
            })
        
        # âœ… æ­¥éª¤ 0: è§„èŒƒåŒ–è¾“å…¥æ•°æ®
        from search.normalize import normalize_opengraph_items
        normalized_items = normalize_opengraph_items(request.opengraph_items)
        print(f"[API] Normalized {len(normalized_items)} items from {len(request.opengraph_items)} input items")
        
        # 1. è°ƒç”¨ process_opengraph_for_search() ç”Ÿæˆ embedding
        enriched_items = await process_opengraph_for_search(normalized_items)
        print(f"[API] Generated embeddings for {len(enriched_items)} items")
        
        # 2. å‡†å¤‡æ‰¹é‡å­˜å‚¨çš„æ•°æ®ï¼ˆä½¿ç”¨è§„èŒƒåŒ–åçš„æ•°æ®ï¼‰
        items_to_store = []
        for item in enriched_items:
            # åªå­˜å‚¨æœ‰ embedding çš„é¡¹
            if item.get("text_embedding") or item.get("image_embedding"):
                # ç¡®ä¿ metadata åŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
                metadata = item.get("metadata") or {}
                if not isinstance(metadata, dict):
                    metadata = {}
                
                items_to_store.append({
                    "url": item.get("url"),
                    "title": item.get("title"),
                    "description": item.get("description"),
                    "image": item.get("image"),  # âœ… å·²ç»æ˜¯è§„èŒƒåŒ–åçš„å­—ç¬¦ä¸²
                    "site_name": item.get("site_name"),
                    "tab_id": item.get("tab_id"),
                    "tab_title": item.get("tab_title"),
                    "text_embedding": item.get("text_embedding"),
                    "image_embedding": item.get("image_embedding"),
                    "metadata": {
                        **metadata,
                        "is_screenshot": item.get("is_screenshot", False),
                        "is_doc_card": item.get("is_doc_card", False),
                        "success": item.get("success", False),
                    }
                })
        
        # 3. è°ƒç”¨ batch_upsert_items() å­˜å‚¨åˆ°æ•°æ®åº“
        saved_count = 0
        db_host = os.getenv("ADBPG_HOST", "")
        if db_host and items_to_store:
            try:
                from vector_db import batch_upsert_items
                saved_count = await batch_upsert_items(items_to_store)
                if saved_count > 0:
                    print(f"[API] âœ“ Stored {saved_count}/{len(items_to_store)} items to vector DB")
                else:
                    print(f"[API] âš  Failed to store items to vector DB (saved_count=0)")
            except Exception as e:
                print(f"[API] âš  Failed to store embeddings to DB: {e}")
                import traceback
                traceback.print_exc()
        elif not db_host:
            print(f"[API] âš  ADBPG_HOST not configured, skipping database storage")
        elif not items_to_store:
            print(f"[API] âš  No items with embeddings to store")
        
        # 4. æ ¼å¼åŒ–è¿”å›æ•°æ®
        result_data = []
        for item in enriched_items:
            has_text_emb = item.get("text_embedding") and len(item.get("text_embedding", [])) > 0
            has_image_emb = item.get("image_embedding") and len(item.get("image_embedding", [])) > 0
            has_emb_flag = item.get("has_embedding", False)
            
            if not has_emb_flag and (has_text_emb or has_image_emb):
                has_emb_flag = True
            
            result_data.append({
                "url": item.get("url"),
                "title": item.get("title") or item.get("tab_title", ""),
                "description": item.get("description", ""),
                "image": item.get("image", ""),
                "site_name": item.get("site_name", ""),
                "tab_id": item.get("tab_id"),
                "tab_title": item.get("tab_title"),
                "embedding": None,  # ä¸å†ä½¿ç”¨èåˆ embedding
                "text_embedding": item.get("text_embedding"),
                "image_embedding": item.get("image_embedding"),
                "has_embedding": has_emb_flag,
                "similarity": item.get("similarity")
            })
        
        # 5. è¿”å›åŒ…å« saved å­—æ®µçš„å“åº”
        return {
            "ok": True,
            "saved": saved_count,
            "data": result_data
        }
    except Exception as e:
        print(f"[API] CRITICAL ERROR in generate_embeddings: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        error_detail = f"{type(e).__name__}: {str(e)}"
        raise HTTPException(status_code=500, detail=error_detail)


@app.post("/api/v1/search/query")
async def search_content(request: SearchRequest):
    """
    æœç´¢ç›¸å…³å†…å®¹ï¼ˆä»å‘é‡æ•°æ®åº“æ£€ç´¢ï¼‰
    
    è¯·æ±‚å‚æ•°:
    - query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¿…éœ€ï¼‰
    - top_k: è¿”å›å‰ K ä¸ªç»“æœï¼ˆå¯é€‰ï¼Œé»˜è®¤ 20ï¼‰
    
    è¿”å›:
    - æŒ‰ç›¸å…³æ€§æ’åºçš„OpenGraphæ•°æ®åˆ—è¡¨ï¼ˆåŒ…å«similarityåˆ†æ•°ï¼‰
    """
    try:
        if not request.query or not request.query.strip():
            raise HTTPException(status_code=400, detail="query parameter is required")
        
        top_k = request.top_k or 20
        print(f"[API] Search request: query='{request.query}', top_k={top_k}")
        
        # æ£€æŸ¥æ•°æ®åº“é…ç½®
        db_host = os.getenv("ADBPG_HOST", "")
        if not db_host:
            raise HTTPException(
                status_code=503,
                detail="Vector database not configured. Please set ADBPG_HOST environment variable."
            )
        
        # 1. ä½¿ç”¨ embed_text() ç”ŸæˆæŸ¥è¯¢çš„æ–‡æœ¬ embedding
        from search.embed import embed_text
        from vector_db import search_by_text_embedding
        
        query_embedding = await embed_text(request.query)
        if not query_embedding:
            raise HTTPException(
                status_code=500,
                detail="Failed to generate query embedding"
            )
        
        print(f"[API] Generated query embedding (dimension: {len(query_embedding)})")
        
        # 2. ä½¿ç”¨ search_by_text_embedding() ä»æ•°æ®åº“æ£€ç´¢
        db_results = await search_by_text_embedding(query_embedding, top_k=top_k)
        
        if not db_results:
            print(f"[API] No results found in database for query: '{request.query}'")
            return {
                "ok": True,
                "results": []
            }
        
        print(f"[API] Found {len(db_results)} results from vector DB")
        
        # 3. æ ¼å¼åŒ–è¿”å›ç»“æœï¼ˆä¿æŒä¸å‰ç«¯ useSearch å…¼å®¹ï¼‰
        results = []
        for item in db_results:
            results.append({
                "url": item.get("url", ""),
                "title": item.get("title") or item.get("tab_title", ""),
                "description": item.get("description", ""),
                "image": item.get("image", ""),
                "site_name": item.get("site_name", ""),
                "tab_id": item.get("tab_id"),
                "tab_title": item.get("tab_title"),
                "similarity": float(item.get("similarity", 0.0))
            })
        
        # æ‰“å°ç›¸ä¼¼åº¦èŒƒå›´ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if results:
            similarities = [r.get("similarity", 0.0) for r in results]
            print(f"[API] Similarity range: min={min(similarities):.6f}, max={max(similarities):.6f}")
        
        # 4. è¿”å› JSON å“åº”
        return {
            "ok": True,
            "results": results
        }
    except Exception as e:
        print(f"[API] Error searching: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


# èšç±» API
class ManualClusterRequest(BaseModel):
    item_ids: List[str]
    cluster_name: str
    items_data: List[Dict[str, Any]]
    center_x: Optional[float] = 720
    center_y: Optional[float] = 512


class AIClassifyRequest(BaseModel):
    labels: List[str]
    items_data: List[Dict[str, Any]]
    exclude_item_ids: Optional[List[str]] = None


class AIDiscoverRequest(BaseModel):
    items_data: List[Dict[str, Any]]
    exclude_item_ids: Optional[List[str]] = None
    n_clusters: Optional[int] = None


@app.post("/api/v1/clustering/manual")
async def create_manual_cluster_api(request: ManualClusterRequest):
    """
    åˆ›å»ºç”¨æˆ·è‡ªå®šä¹‰èšç±»
    
    è¯·æ±‚å‚æ•°:
    - item_ids: é€‰ä¸­çš„å¡ç‰‡ ID åˆ—è¡¨
    - cluster_name: èšç±»åç§°
    - items_data: æ‰€æœ‰å¡ç‰‡æ•°æ®
    - center_x: èšç±»ä¸­å¿ƒ X åæ ‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 720ï¼‰
    - center_y: èšç±»ä¸­å¿ƒ Y åæ ‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 512ï¼‰
    
    è¿”å›:
    - èšç±»å¯¹è±¡ï¼ŒåŒ…å« id, name, type, items, center, radius ç­‰ä¿¡æ¯
    """
    try:
        if not request.item_ids or not request.cluster_name:
            raise HTTPException(status_code=400, detail="item_ids and cluster_name are required")
        
        cluster = create_manual_cluster(
            item_ids=request.item_ids,
            cluster_name=request.cluster_name,
            items_data=request.items_data,
            center_x=request.center_x or 720,
            center_y=request.center_y or 512,
        )
        
        # ä¿å­˜ç»“æœåˆ°æœ¬åœ°
        try:
            save_clustering_result(cluster, result_type="manual")
        except Exception as save_error:
            print(f"[API] Failed to save clustering result: {save_error}")
        
        return {"ok": True, "cluster": cluster}
    except Exception as e:
        print(f"[API] ERROR in create_manual_cluster: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/clustering/ai-classify")
async def classify_by_labels_api(request: AIClassifyRequest):
    """
    AI æŒ‰æ ‡ç­¾åˆ†ç±»
    
    è¯·æ±‚å‚æ•°:
    - labels: ç”¨æˆ·å®šä¹‰çš„æ ‡ç­¾åˆ—è¡¨ï¼ˆæœ€å¤š3ä¸ªï¼‰
    - items_data: æ‰€æœ‰å¡ç‰‡æ•°æ®ï¼ˆéœ€è¦åŒ…å« text_embedding å’Œ image_embeddingï¼‰
    - exclude_item_ids: è¦æ’é™¤çš„å¡ç‰‡ ID åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¾‹å¦‚ç”¨æˆ·è‡ªå®šä¹‰èšç±»ä¸­çš„å¡ç‰‡ï¼‰
    
    è¿”å›:
    - åˆ†ç±»ç»“æœï¼ŒåŒ…å«æ¯ä¸ªæ ‡ç­¾å¯¹åº”çš„èšç±»
    """
    try:
        if not request.labels or len(request.labels) == 0:
            raise HTTPException(status_code=400, detail="labels are required")
        
        result = await classify_by_labels(
            labels=request.labels,
            items_data=request.items_data,
            exclude_item_ids=request.exclude_item_ids,
        )
        
        # ä¿å­˜ç»“æœåˆ°æœ¬åœ°
        try:
            save_multiple_clusters(result.get("clusters", []), result_type="ai-classify")
        except Exception as save_error:
            print(f"[API] Failed to save clustering result: {save_error}")
        
        return {"ok": True, **result}
    except Exception as e:
        print(f"[API] ERROR in classify_by_labels: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/clustering/ai-discover")
async def discover_clusters_api(request: AIDiscoverRequest):
    """
    AI è‡ªå‘ç°èšç±»ï¼ˆä½¿ç”¨ K-means å¯¹æ‰€æœ‰å¡ç‰‡è¿›è¡Œæ— ç›‘ç£èšç±»ï¼‰
    
    è¯·æ±‚å‚æ•°:
    - items_data: æ‰€æœ‰å¡ç‰‡æ•°æ®ï¼ˆéœ€è¦åŒ…å« text_embedding å’Œ image_embeddingï¼‰
    - exclude_item_ids: è¦æ’é™¤çš„å¡ç‰‡ ID åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¾‹å¦‚ç”¨æˆ·è‡ªå®šä¹‰èšç±»ä¸­çš„å¡ç‰‡ï¼‰
    - n_clusters: èšç±»æ•°é‡ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šï¼Œè‡ªåŠ¨ç¡®å®š3-5ç»„ï¼‰
    
    è¿”å›:
    - èšç±»ç»“æœï¼ŒåŒ…å«æ¯ä¸ªèšç±»çš„ä¿¡æ¯ï¼ˆåŒ…æ‹¬ AI ç”Ÿæˆçš„åç§°ï¼‰
    """
    try:
        if not request.items_data:
            raise HTTPException(status_code=400, detail="items_data is required")
        
        result = await discover_clusters(
            items_data=request.items_data,
            exclude_item_ids=request.exclude_item_ids,
            n_clusters=request.n_clusters,
        )
        
        # ä¿å­˜ç»“æœåˆ°æœ¬åœ°
        try:
            save_multiple_clusters(result.get("clusters", []), result_type="ai-discover")
        except Exception as save_error:
            print(f"[API] Failed to save clustering result: {save_error}")
        
        return {"ok": True, **result}
    except Exception as e:
        print(f"[API] ERROR in discover_clusters: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
