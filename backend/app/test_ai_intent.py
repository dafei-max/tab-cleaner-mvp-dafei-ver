"""
æµ‹è¯• AI æ„å›¾å¢å¼ºåŠŸèƒ½
"""
import asyncio
import sys
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

parent_dir = Path(__file__).parent
sys.path.insert(0, str(parent_dir))

from search.ai_intent_enhance import hybrid_intent_detection, validate_search_results_with_ai


async def test_ai_intent_enhancement():
    """æµ‹è¯• AI æ„å›¾å¢å¼º"""
    print("=" * 80)
    print("ğŸ§ª æµ‹è¯• AI æ„å›¾å¢å¼ºåŠŸèƒ½")
    print("=" * 80)
    
    test_queries = [
        "ç»¿è‰²æ¤ç‰©",
        "ç®€çº¦è®¾è®¡",
        "è“è‰²æ¤…å­",
        "ç°ä»£é£æ ¼",
        "çº¢è‰²èƒŒæ™¯",
    ]
    
    for query in test_queries:
        print(f"\n{'=' * 80}")
        print(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: {query}")
        print(f"{'=' * 80}")
        
        try:
            result = await hybrid_intent_detection(
                query,
                use_ai=True,
                ai_timeout=5.0,  # 5ç§’è¶…æ—¶
                cache={}
            )
            
            print(f"\nâœ… ç»“æœ:")
            print(f"  åŸå§‹æŸ¥è¯¢: {result['original_query']}")
            print(f"  å¢å¼ºæŸ¥è¯¢: {result['enhanced_query']}")
            print(f"  æŸ¥è¯¢ç±»å‹: {result['query_type']}")
            print(f"  AIå¢å¼º: {result.get('ai_enhanced', False)}")
            print(f"  è§„åˆ™å¼: {result.get('rule_based', False)}")
            
            # æ˜¾ç¤ºæ€ç»´é“¾ï¼ˆå¦‚æœæœ‰ï¼‰
            thinking_chain = result.get('thinking_chain', {})
            if thinking_chain:
                print(f"\n  æ€ç»´é“¾:")
                print(f"    ç”¨æˆ·æ„å›¾: {thinking_chain.get('user_intent', 'N/A')}")
                print(f"    ä½¿ç”¨åœºæ™¯: {thinking_chain.get('use_case', 'N/A')}")
                print(f"    éšå«éœ€æ±‚: {thinking_chain.get('implicit_needs', 'N/A')}")
            
            # æ˜¾ç¤ºç›¸å…³è¯æ¡ï¼ˆæ–°æ ¼å¼ï¼‰
            related_keywords = result.get('related_keywords', [])
            if related_keywords:
                print(f"\n  ç›¸å…³è¯æ¡ ({len(related_keywords)}ä¸ª):")
                for i, kw in enumerate(related_keywords, 1):
                    print(f"    {i}. {kw}")
            
            extracted = result.get('extracted_info', {})
            print(f"\n  æå–ä¿¡æ¯:")
            print(f"    é¢œè‰²: {extracted.get('colors', [])}")
            print(f"    ç‰©ä½“: {extracted.get('objects', [])}")
            print(f"    é£æ ¼: {extracted.get('styles', [])}")
            print(f"    æ¦‚å¿µ: {extracted.get('concepts', [])}")
            
            suggestions = result.get('search_suggestions', {})
            print(f"\n  æœç´¢å»ºè®®:")
            print(f"    ä¼˜å…ˆç½‘ç«™: {suggestions.get('prioritize_sites', [])}")
            print(f"    è¿‡æ»¤ç±»å‹: {suggestions.get('filter_types', [])}")
            print(f"    ç›¸ä¼¼åº¦é˜ˆå€¼: {suggestions.get('similarity_threshold', 0.3)}")
            
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\n{'=' * 80}")
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)


async def test_result_validation():
    """æµ‹è¯•æœç´¢ç»“æœéªŒè¯"""
    print("\n" + "=" * 80)
    print("ğŸ§ª æµ‹è¯•æœç´¢ç»“æœéªŒè¯åŠŸèƒ½")
    print("=" * 80)
    
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    mock_results = [
        {
            "title": "ç»¿è‰²æ¤ç‰©å®¤å†…è®¾è®¡",
            "url": "https://pinterest.com/pin/123",
            "similarity": 0.85,
            "site_name": "Pinterest",
            "description": "ç¾ä¸½çš„ç»¿è‰²æ¤ç‰©å®¤å†…è£…é¥°",
            "dominant_colors": ["green"],
            "object_tags": ["plant", "tree"],
            "style_tags": ["modern"],
        },
        {
            "title": "React API æ–‡æ¡£",
            "url": "https://react.dev/docs",
            "similarity": 0.65,
            "site_name": "React",
            "description": "React å®˜æ–¹æ–‡æ¡£",
            "dominant_colors": [],
            "object_tags": [],
            "style_tags": [],
        },
        {
            "title": "çº¢è‰²èƒŒæ™¯è®¾è®¡",
            "url": "https://behance.net/project/456",
            "similarity": 0.70,
            "site_name": "Behance",
            "description": "çº¢è‰²èƒŒæ™¯çš„åˆ›æ„è®¾è®¡",
            "dominant_colors": ["red"],
            "object_tags": ["background"],
            "style_tags": ["creative"],
        },
    ]
    
    query = "ç»¿è‰²æ¤ç‰©"
    
    print(f"\næŸ¥è¯¢: {query}")
    print(f"ç»“æœæ•°é‡: {len(mock_results)}")
    
    try:
        validation = await validate_search_results_with_ai(
            query,
            mock_results,
            top_n=3
        )
        
        print(f"\nâœ… éªŒè¯ç»“æœ:")
        print(f"  AIéªŒè¯: {validation.get('ai_validated', False)}")
        print(f"  ç›¸å…³ç»“æœç´¢å¼•: {validation.get('relevant_indices', [])}")
        print(f"  è¿‡æ»¤ç»“æœç´¢å¼•: {validation.get('filter_out_indices', [])}")
        print(f"  æå‡ä¼˜å…ˆçº§ç´¢å¼•: {validation.get('boost_indices', [])}")
        
        # æ˜¾ç¤ºéªŒè¯åçš„ç»“æœ
        print(f"\n  éªŒè¯åçš„ç»“æœ:")
        for idx in validation.get('relevant_indices', []):
            if 0 <= idx < len(mock_results):
                item = mock_results[idx]
                print(f"    âœ… [{idx}] {item['title']} (ç›¸ä¼¼åº¦: {item['similarity']:.3f})")
        
        for idx in validation.get('filter_out_indices', []):
            if 0 <= idx < len(mock_results):
                item = mock_results[idx]
                print(f"    âŒ [{idx}] {item['title']} (è¢«è¿‡æ»¤)")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\n{'=' * 80}")
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)


async def main():
    """ä¸»å‡½æ•°"""
    await test_ai_intent_enhancement()
    await test_result_validation()


if __name__ == "__main__":
    asyncio.run(main())

