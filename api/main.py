# Vercel å…¥å£æ–‡ä»¶ï¼šæ·»åŠ  backend/app åˆ° Python è·¯å¾„
import sys
from pathlib import Path

# æ·»åŠ  backend/app ç›®å½•åˆ° Python è·¯å¾„
backend_app_path = Path(__file__).parent.parent / "backend" / "app"
sys.path.insert(0, str(backend_app_path))

# å¯¼å…¥çœŸæ­£çš„åº”ç”¨
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from datetime import datetime
import json
import os
from opengraph import fetch_multiple_opengraph
from ai_insight import analyze_opengraph_data
from search import process_opengraph_for_search, search_relevant_items
from clustering import create_manual_cluster, classify_by_labels, discover_clusters
from clustering.storage import save_clustering_result, save_multiple_clusters

app = FastAPI(title="Tab Cleaner MVP", version="0.0.1")


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
    try:
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†æ•°æ®åº“è¿æ¥
        db_host = os.getenv("ADBPG_HOST", "")
        if db_host:
            try:
                from vector_db import init_schema
                print("[Startup] Initializing vector database...")
                await init_schema()
                print("[Startup] âœ“ Vector database initialized successfully")
            except ImportError as import_error:
                print(f"[Startup] âš  Vector DB module import failed: {import_error}")
                print("[Startup] âš  This is expected if asyncpg is not installed. Vector DB features will be disabled.")
                print("[Startup] âš  To enable vector DB, ensure asyncpg is installed: pip install asyncpg>=0.30.0")
            except Exception as db_error:
                print(f"[Startup] âš  Vector DB initialization failed: {db_error}")
                print("[Startup] âš  Continuing without vector database...")
                import traceback
                traceback.print_exc()
        else:
            print("[Startup] ADBPG_HOST not configured, skipping vector database initialization")
    except Exception as e:
        print(f"[Startup] âš  Startup event error (non-critical): {e}")
        # ä¸é˜»æ­¢åº”ç”¨å¯åŠ¨


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶æ¸…ç†èµ„æº"""
    try:
        from vector_db import close_pool
        await close_pool()
        print("[Shutdown] Vector database connection pool closed")
    except Exception as e:
        print(f"[Shutdown] Error closing vector database: {e}")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# serve static pages (for share link)
# æ³¨æ„ï¼šå¦‚æœä¸éœ€è¦é™æ€æ–‡ä»¶æœåŠ¡ï¼Œå¯ä»¥åˆ é™¤ static ç›®å½•
static_dir = Path(__file__).parent / "static"
# åªæœ‰å½“ static ç›®å½•å­˜åœ¨ä¸”ä¸ä¸ºç©ºæ—¶æ‰æŒ‚è½½
if static_dir.exists() and static_dir.is_dir():
    try:
        app.mount("/public", StaticFiles(directory=static_dir, html=True), name="public")
    except Exception as e:
        # å¦‚æœæŒ‚è½½å¤±è´¥ï¼ˆä¾‹å¦‚ç›®å½•ä¸ºç©ºï¼‰ï¼Œè®°å½•è­¦å‘Šä½†ä¸å½±å“åº”ç”¨å¯åŠ¨
        print(f"[Warning] Failed to mount static directory: {e}")

@app.get("/")
def root():
    return {"ok": True, "message": "Hello Tab Cleaner"}


@app.get("/favicon.ico")
async def favicon():
    """è¿”å› favicon å›¾æ ‡"""
    # ä¼˜å…ˆå°è¯• .ico æ ¼å¼
    favicon_path = Path(__file__).parent / "static" / "favicon.ico"
    if not favicon_path.exists():
        # å¦‚æœæ²¡æœ‰ .icoï¼Œå°è¯• .png
        favicon_path = Path(__file__).parent / "static" / "favicon.png"
    
    if favicon_path.exists():
        return FileResponse(favicon_path)
    # å¦‚æœæ²¡æœ‰ faviconï¼Œè¿”å› 204 No Content
    from fastapi.responses import Response
    return Response(status_code=204)


# OpenGraph API
class TabItem(BaseModel):
    url: str
    title: Optional[str] = None
    id: Optional[int] = None


class OpenGraphRequest(BaseModel):
    tabs: List[TabItem]
    # å¯é€‰ï¼šå‰ç«¯å·²æŠ“å–çš„ OpenGraph æ•°æ®ï¼ˆç”¨äºéœ€è¦ç™»å½•çš„ç½‘ç«™ï¼‰
    local_opengraph_data: Optional[List[Dict[str, Any]]] = None


@app.post("/api/v1/tabs/opengraph")
async def fetch_tabs_opengraph(request: OpenGraphRequest):
    """
    æ‰¹é‡æŠ“å–å¤šä¸ª tabs çš„ OpenGraph æ•°æ®
    å¦‚æœæä¾›äº† local_opengraph_dataï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°æŠ“å–çš„æ•°æ®ï¼ˆç”¨äºéœ€è¦ç™»å½•çš„ç½‘ç«™ï¼‰
    """
    try:
        urls = [tab.url for tab in request.tabs]
        if not urls:
            return {"ok": True, "data": []}
        
        # å¦‚æœæœ‰æœ¬åœ°æŠ“å–çš„æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨
        if request.local_opengraph_data and len(request.local_opengraph_data) > 0:
            print(f"[API] Using local OpenGraph data for {len(request.local_opengraph_data)} items")
            opengraph_data = []
            
            # åˆ›å»ºæœ¬åœ°æ•°æ®çš„ URL æ˜ å°„
            local_data_map = {item.get("url"): item for item in request.local_opengraph_data if item.get("url")}
            
            # å°†æœ¬åœ°æ•°æ®ä¸ tab ä¿¡æ¯åˆå¹¶
            for i, tab in enumerate(request.tabs):
                local_item = local_data_map.get(tab.url)
                
                if local_item:
                    # ç¡®ä¿å­—æ®µæ˜ å°„æ­£ç¡®ï¼ˆæœ¬åœ°æŠ“å–è¿”å›çš„å­—æ®µåå¯èƒ½ä¸åç«¯ä¸€è‡´ï¼‰
                    opengraph_data.append({
                        "url": local_item.get("url") or tab.url,
                        "title": local_item.get("title") or local_item.get("og:title") or tab.title or "",
                        "description": local_item.get("description") or local_item.get("og:description") or "",
                        "image": local_item.get("image") or local_item.get("og:image") or local_item.get("thumbnail_url") or "",
                        "site_name": local_item.get("site_name") or local_item.get("og:site_name") or "",
                        "tab_id": tab.id,
                        "tab_title": tab.title,
                        "success": local_item.get("success", True),
                        "is_local_fetch": True,  # æ ‡è®°ä¸ºæœ¬åœ°æŠ“å–
                    })
                else:
                    # å¦‚æœæ²¡æœ‰æœ¬åœ°æ•°æ®ï¼Œä½¿ç”¨åç«¯æŠ“å–
                    results = await fetch_multiple_opengraph([tab.url])
                    if results and len(results) > 0:
                        opengraph_data.append({
                            **results[0],
                            "tab_id": tab.id,
                            "tab_title": tab.title,
                            "is_screenshot": results[0].get("is_screenshot", False),
                        })
            
            print(f"[API] Processed {len(opengraph_data)} items (local fetch)")
            
            # ğŸ”„ å¯¹äºæœ¬åœ°æŠ“å–çš„æ•°æ®ï¼Œä¹Ÿéœ€è¦ç”Ÿæˆ embedding å¹¶å­˜å‚¨åˆ°æ•°æ®åº“
            # æ¨¡æ‹Ÿ fetch_opengraph çš„è¡Œä¸ºï¼Œè§¦å‘ embedding é¢„å–
            try:
                from opengraph import _prefetch_embedding
                import asyncio
                # å¼‚æ­¥è§¦å‘ embedding é¢„å–ï¼ˆä¸é˜»å¡å“åº”ï¼‰
                for item in opengraph_data:
                    if item.get("success") and item.get("is_local_fetch"):
                        # åˆ›å»ºåå°ä»»åŠ¡ï¼Œä¸ç­‰å¾…å®Œæˆï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
                        asyncio.create_task(_prefetch_embedding(item))
                print(f"[API] Triggered embedding prefetch for {sum(1 for item in opengraph_data if item.get('success') and item.get('is_local_fetch'))} local items")
            except Exception as e:
                print(f"[API] Warning: Failed to prefetch embeddings for local data: {e}")
                import traceback
                traceback.print_exc()
        else:
            # æ²¡æœ‰æœ¬åœ°æ•°æ®ï¼Œä½¿ç”¨åç«¯æŠ“å–
            results = await fetch_multiple_opengraph(urls)
            
            # å°†ç»“æœä¸åŸå§‹ tab ä¿¡æ¯åˆå¹¶
            opengraph_data = []
            for i, result in enumerate(results):
                opengraph_data.append({
                    **result,
                    "tab_id": request.tabs[i].id,
                    "tab_title": request.tabs[i].title,
                    "is_screenshot": result.get("is_screenshot", False),
                })
            
            print(f"[API] Processed {len(opengraph_data)} items (backend fetch)")
        
        # ç»Ÿè®¡æˆªå›¾æ•°é‡
        screenshot_count = sum(1 for item in opengraph_data if item.get("is_screenshot", False))
        local_count = sum(1 for item in opengraph_data if item.get("is_local_fetch", False))
        print(f"[API] OpenGraph data: {len(opengraph_data)} items, {screenshot_count} screenshots, {local_count} local fetches")
        
        return {"ok": True, "data": opengraph_data}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# AI æ´å¯Ÿ API
class AIInsightRequest(BaseModel):
    opengraph_items: List[Dict[str, Any]]


@app.post("/api/v1/ai/insight")
async def get_ai_insight(request: AIInsightRequest):
    """
    ä½¿ç”¨é€šä¹‰åƒé—®åˆ†æ OpenGraph æ•°æ®å¹¶ç”Ÿæˆæ€»ç»“
    """
    try:
        if not request.opengraph_items:
            raise HTTPException(status_code=400, detail="No OpenGraph items provided")
        
        result = analyze_opengraph_data(request.opengraph_items)
        
        if result["success"]:
            return {
                "ok": True,
                "summary": result["summary"],
                "error": None
            }
        else:
            return {
                "ok": False,
                "summary": None,
                "error": result.get("error", "Unknown error")
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# æœç´¢ API
class EmbeddingRequest(BaseModel):
    opengraph_items: List[Dict[str, Any]]


class SearchRequest(BaseModel):
    query_text: Optional[str] = None
    query_image_url: Optional[str] = None
    opengraph_items: List[Dict[str, Any]]


@app.post("/api/v1/search/embedding")
async def generate_embeddings(request: EmbeddingRequest):
    """
    ä¸ºOpenGraphæ•°æ®ç”ŸæˆEmbeddingå‘é‡ï¼ˆæ‰¹é‡å¤„ç†ï¼‰
    ä¼˜å…ˆä»å‘é‡æ•°æ®åº“è¯»å–ï¼Œå¦‚æœæ²¡æœ‰æ‰ç”Ÿæˆæ–°çš„
    """
    try:
        if not request.opengraph_items:
            return {"ok": True, "data": []}
        
        print(f"[API] Processing {len(request.opengraph_items)} items (checking DB first)")
        
        # ä¼˜å…ˆä»æ•°æ®åº“è¯»å– embeddingï¼ˆå¦‚æœæ•°æ®åº“é…ç½®äº†ï¼‰
        result_data = []
        items_to_process = []  # éœ€è¦ç”Ÿæˆ embedding çš„é¡¹
        
        db_host = os.getenv("ADBPG_HOST", "")
        print(f"[API] ADBPG_HOST configured: {bool(db_host)}")
        if db_host:
            try:
                from vector_db import get_opengraph_item
                
                for item in request.opengraph_items:
                    url = item.get("url")
                    if not url:
                        continue
                    
                    # å°è¯•ä»æ•°æ®åº“è¯»å–
                    try:
                        db_item = await get_opengraph_item(url)
                        if db_item:
                            has_text_emb = db_item.get("text_embedding") and len(db_item.get("text_embedding", [])) > 0
                            has_image_emb = db_item.get("image_embedding") and len(db_item.get("image_embedding", [])) > 0
                            if has_text_emb or has_image_emb:
                                # æ•°æ®åº“æœ‰ embeddingï¼Œç›´æ¥ä½¿ç”¨
                                print(f"[API] âœ“ Found in DB: {url[:50]}... (text_emb: {has_text_emb}, image_emb: {has_image_emb})")
                                result_data.append({
                                    "url": db_item.get("url"),
                                    "title": db_item.get("title") or item.get("tab_title", ""),
                                    "description": db_item.get("description", ""),
                                    "image": db_item.get("image", ""),
                                    "site_name": db_item.get("site_name", ""),
                                    "tab_id": db_item.get("tab_id") or item.get("tab_id"),
                                    "tab_title": db_item.get("tab_title") or item.get("tab_title"),
                                    "embedding": None,
                                    "text_embedding": db_item.get("text_embedding"),
                                    "image_embedding": db_item.get("image_embedding"),
                                    "has_embedding": True,
                                    "similarity": item.get("similarity")
                                })
                                continue
                            else:
                                print(f"[API] âš  DB item exists but no embeddings: {url[:50]}...")
                        else:
                            print(f"[API] âš  Not found in DB: {url[:50]}...")
                    except Exception as db_error:
                        print(f"[API] âœ— DB read error for {url[:50]}...: {db_error}")
                        import traceback
                        traceback.print_exc()
                    
                    # æ•°æ®åº“æ²¡æœ‰ï¼Œéœ€è¦ç”Ÿæˆ
                    items_to_process.append(item)
            except Exception as db_init_error:
                print(f"[API] Vector DB not available: {db_init_error}, processing all items")
                items_to_process = request.opengraph_items
        else:
            # æ•°æ®åº“æœªé…ç½®ï¼Œå¤„ç†æ‰€æœ‰é¡¹
            items_to_process = request.opengraph_items
        
        # ä¸ºæ²¡æœ‰ embedding çš„é¡¹ç”Ÿæˆ embedding
        if items_to_process:
            print(f"[API] Generating embeddings for {len(items_to_process)} new items")
            processed_items = await process_opengraph_for_search(items_to_process)
            
            # å­˜å‚¨åˆ°æ•°æ®åº“ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            if db_host:
                try:
                    from vector_db import upsert_opengraph_item
                    stored_count = 0
                    for item in processed_items:
                        if item.get("text_embedding") or item.get("image_embedding"):
                            success = await upsert_opengraph_item(
                                url=item.get("url"),
                                title=item.get("title"),
                                description=item.get("description"),
                                image=item.get("image"),
                                site_name=item.get("site_name"),
                                tab_id=item.get("tab_id"),
                                tab_title=item.get("tab_title"),
                                text_embedding=item.get("text_embedding"),
                                image_embedding=item.get("image_embedding"),
                                metadata={
                                    "is_screenshot": item.get("is_screenshot", False),
                                    "is_doc_card": item.get("is_doc_card", False),
                                    "success": item.get("success", False),
                                }
                            )
                            if success:
                                stored_count += 1
                    if stored_count > 0:
                        print(f"[API] âœ“ Stored {stored_count} items to vector DB")
                except Exception as e:
                    print(f"[API] âš  Failed to store embeddings to DB: {e}")
                    import traceback
                    traceback.print_exc()
            
            # æ·»åŠ åˆ°ç»“æœä¸­
            for item in processed_items:
                has_text_emb = item.get("text_embedding") and len(item.get("text_embedding", [])) > 0
                has_image_emb = item.get("image_embedding") and len(item.get("image_embedding", [])) > 0
                has_emb_flag = item.get("has_embedding", False)
                
                if not has_emb_flag and (has_text_emb or has_image_emb):
                    # å¦‚æœ has_embedding æ ‡å¿—ä¸º False ä½†å®é™…æœ‰ embeddingï¼Œæ›´æ–°æ ‡å¿—
                    has_emb_flag = True
                
                result_data.append({
                    "url": item.get("url"),
                    "title": item.get("title") or item.get("tab_title", ""),
                    "description": item.get("description", ""),
                    "image": item.get("image", ""),
                    "site_name": item.get("site_name", ""),
                    "tab_id": item.get("tab_id"),
                    "tab_title": item.get("tab_title"),
                    "embedding": None,  # ä¸å†ä½¿ç”¨èåˆ embedding
                    "text_embedding": item.get("text_embedding"),
                    "image_embedding": item.get("image_embedding"),
                    "has_embedding": has_emb_flag,
                    "similarity": item.get("similarity")
                })
        
        # ç»Ÿè®¡ä¿¡æ¯
        items_with_embedding = sum(1 for r in result_data if 
            r.get("has_embedding", False) or
            (r.get("text_embedding") and len(r.get("text_embedding", [])) > 0) or
            (r.get("image_embedding") and len(r.get("image_embedding", [])) > 0)
        )
        items_with_text_emb = sum(1 for r in result_data if 
            r.get("text_embedding") and len(r.get("text_embedding", [])) > 0
        )
        items_with_image_emb = sum(1 for r in result_data if 
            r.get("image_embedding") and len(r.get("image_embedding", [])) > 0
        )
        from_db = len(result_data) - len(items_to_process) if items_to_process else len(result_data)
        newly_generated = len(items_to_process) if items_to_process else 0
        
        print(f"[API] ===== Summary =====")
        print(f"[API] Total items returned: {len(result_data)}")
        print(f"[API]   - From DB: {from_db}")
        print(f"[API]   - Newly generated: {newly_generated}")
        print(f"[API] Items with embedding: {items_with_embedding}")
        print(f"[API]   - With text_embedding: {items_with_text_emb}")
        print(f"[API]   - With image_embedding: {items_with_image_emb}")
        if len(result_data) > 0:
            sample = result_data[0]
            print(f"[API] Sample item: {sample.get('url', '')[:50]}...")
            print(f"[API]   - has_embedding flag: {sample.get('has_embedding')}")
            print(f"[API]   - text_embedding: {bool(sample.get('text_embedding'))} (length: {len(sample.get('text_embedding', []))})")
            print(f"[API]   - image_embedding: {bool(sample.get('image_embedding'))} (length: {len(sample.get('image_embedding', []))})")
        
        return {"ok": True, "data": result_data}
    except Exception as e:
        print(f"[API] CRITICAL ERROR in generate_embeddings: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        error_detail = f"{type(e).__name__}: {str(e)}"
        raise HTTPException(status_code=500, detail=error_detail)


@app.post("/api/v1/search/query")
async def search_content(request: SearchRequest):
    """
    æœç´¢ç›¸å…³å†…å®¹ï¼ˆæ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡æŸ¥è¯¢ï¼‰
    ä¼˜å…ˆä»å‘é‡æ•°æ®åº“æœç´¢ï¼Œå¦‚æœæ²¡æœ‰ç»“æœå†ä½¿ç”¨ä¼ å…¥çš„ opengraph_items
    
    è¯·æ±‚å‚æ•°:
    - query_text: æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
    - query_image_url: æŸ¥è¯¢å›¾ç‰‡URLï¼ˆå¯é€‰ï¼Œè‡³å°‘éœ€è¦æä¾›query_textæˆ–query_image_urlä¹‹ä¸€ï¼‰
    - opengraph_items: åŒ…å«Embeddingçš„OpenGraphæ•°æ®åˆ—è¡¨ï¼ˆä½œä¸ºåå¤‡æ–¹æ¡ˆï¼‰
    
    è¿”å›:
    - æŒ‰ç›¸å…³æ€§æ’åºçš„OpenGraphæ•°æ®åˆ—è¡¨ï¼ˆåŒ…å«similarityåˆ†æ•°ï¼‰
    """
    try:
        if not request.query_text and not request.query_image_url:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦æä¾›query_textæˆ–query_image_urlä¹‹ä¸€")
        
        print(f"[API] Search request: query_text='{request.query_text}', query_image_url={request.query_image_url}")
        
        # ä¼˜å…ˆä»å‘é‡æ•°æ®åº“æœç´¢
        results = []
        db_host = os.getenv("ADBPG_HOST", "")
        
        if db_host:
            try:
                from vector_db import search_by_text_embedding, search_by_image_embedding
                from search.embed import embed_text, embed_image
                from search.preprocess import download_image, process_image
                
                # æ–‡æœ¬æœç´¢
                if request.query_text:
                    try:
                        # ç”ŸæˆæŸ¥è¯¢æ–‡æœ¬çš„ embedding
                        query_emb = await embed_text(request.query_text)
                        if query_emb:
                            # ä»æ•°æ®åº“æœç´¢
                            db_results = await search_by_text_embedding(query_emb, top_k=20)
                            if db_results:
                                print(f"[API] Found {len(db_results)} results from vector DB")
                                results.extend(db_results)
                    except Exception as e:
                        print(f"[API] Vector DB text search failed: {e}, falling back to local search")
                
                # å›¾åƒæœç´¢
                if request.query_image_url:
                    try:
                        # ä¸‹è½½å¹¶å¤„ç†å›¾åƒ
                        image_data = await download_image(request.query_image_url)
                        if image_data:
                            img_b64 = process_image(image_data)
                            if img_b64:
                                # ç”ŸæˆæŸ¥è¯¢å›¾åƒçš„ embedding
                                query_emb = await embed_image(img_b64)
                                if query_emb:
                                    # ä»æ•°æ®åº“æœç´¢
                                    db_results = await search_by_image_embedding(query_emb, top_k=20)
                                    if db_results:
                                        print(f"[API] Found {len(db_results)} image results from vector DB")
                                        results.extend(db_results)
                    except Exception as e:
                        print(f"[API] Vector DB image search failed: {e}, falling back to local search")
            except Exception as e:
                print(f"[API] Vector DB search error: {e}, falling back to local search")
                import traceback
                traceback.print_exc()
        
        # å¦‚æœæ•°æ®åº“æ²¡æœ‰ç»“æœï¼Œä½¿ç”¨ä¼ å…¥çš„ opengraph_items è¿›è¡Œæœ¬åœ°æœç´¢
        if not results and request.opengraph_items:
            print(f"[API] No DB results, using local search with {len(request.opengraph_items)} items")
            results = await search_relevant_items(
                query_text=request.query_text,
                query_image_url=request.query_image_url,
                opengraph_items=request.opengraph_items,
                top_k=20
            )
        
        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        result_data = []
        for item in results[:20]:  # é™åˆ¶è¿”å› 20 ä¸ª
            result_data.append({
                "url": item.get("url"),
                "title": item.get("title") or item.get("tab_title", ""),
                "description": item.get("description", ""),
                "image": item.get("image", ""),
                "site_name": item.get("site_name", ""),
                "tab_id": item.get("tab_id"),
                "tab_title": item.get("tab_title"),
                "similarity": item.get("similarity", 0.0)
            })
        
        # ä¿å­˜æœç´¢ç»“æœåˆ°æœ¬åœ°æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            query_safe = (request.query_text or "empty")[:50].replace("/", "_").replace("\\", "_")
            output_file = Path(__file__).parent / f"search_results_{query_safe}_{timestamp}.json"
            
            output_data = {
                "query": request.query_text,
                "query_image_url": request.query_image_url,
                "timestamp": timestamp,
                "total_results": len(result_data),
                "results": [
                    {
                        "rank": idx + 1,
                        "title": item.get("title") or item.get("tab_title", ""),
                        "url": item.get("url"),
                        "description": item.get("description", ""),
                        "similarity": item.get("similarity", 0.0),
                        "similarity_precise": f"{item.get('similarity', 0.0):.15f}",
                    }
                    for idx, item in enumerate(result_data)
                ]
            }
            
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            print(f"[API] Search results saved to: {output_file}")
            if result_data:
                print(f"[API] Total results: {len(result_data)}, similarity range: "
                      f"min={min(r.get('similarity', 0.0) for r in result_data):.10f}, "
                      f"max={max(r.get('similarity', 0.0) for r in result_data):.10f}")
        except Exception as save_error:
            print(f"[API] Failed to save search results: {save_error}")
        
        return {"ok": True, "data": result_data}
    except Exception as e:
        print(f"[API] Error searching: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


# èšç±» API
class ManualClusterRequest(BaseModel):
    item_ids: List[str]
    cluster_name: str
    items_data: List[Dict[str, Any]]
    center_x: Optional[float] = 720
    center_y: Optional[float] = 512


class AIClassifyRequest(BaseModel):
    labels: List[str]
    items_data: List[Dict[str, Any]]
    exclude_item_ids: Optional[List[str]] = None


class AIDiscoverRequest(BaseModel):
    items_data: List[Dict[str, Any]]
    exclude_item_ids: Optional[List[str]] = None
    n_clusters: Optional[int] = None


@app.post("/api/v1/clustering/manual")
async def create_manual_cluster_api(request: ManualClusterRequest):
    """
    åˆ›å»ºç”¨æˆ·è‡ªå®šä¹‰èšç±»
    
    è¯·æ±‚å‚æ•°:
    - item_ids: é€‰ä¸­çš„å¡ç‰‡ ID åˆ—è¡¨
    - cluster_name: èšç±»åç§°
    - items_data: æ‰€æœ‰å¡ç‰‡æ•°æ®
    - center_x: èšç±»ä¸­å¿ƒ X åæ ‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 720ï¼‰
    - center_y: èšç±»ä¸­å¿ƒ Y åæ ‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 512ï¼‰
    
    è¿”å›:
    - èšç±»å¯¹è±¡ï¼ŒåŒ…å« id, name, type, items, center, radius ç­‰ä¿¡æ¯
    """
    try:
        if not request.item_ids or not request.cluster_name:
            raise HTTPException(status_code=400, detail="item_ids and cluster_name are required")
        
        cluster = create_manual_cluster(
            item_ids=request.item_ids,
            cluster_name=request.cluster_name,
            items_data=request.items_data,
            center_x=request.center_x or 720,
            center_y=request.center_y or 512,
        )
        
        # ä¿å­˜ç»“æœåˆ°æœ¬åœ°
        try:
            save_clustering_result(cluster, result_type="manual")
        except Exception as save_error:
            print(f"[API] Failed to save clustering result: {save_error}")
        
        return {"ok": True, "cluster": cluster}
    except Exception as e:
        print(f"[API] ERROR in create_manual_cluster: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/clustering/ai-classify")
async def classify_by_labels_api(request: AIClassifyRequest):
    """
    AI æŒ‰æ ‡ç­¾åˆ†ç±»
    
    è¯·æ±‚å‚æ•°:
    - labels: ç”¨æˆ·å®šä¹‰çš„æ ‡ç­¾åˆ—è¡¨ï¼ˆæœ€å¤š3ä¸ªï¼‰
    - items_data: æ‰€æœ‰å¡ç‰‡æ•°æ®ï¼ˆéœ€è¦åŒ…å« text_embedding å’Œ image_embeddingï¼‰
    - exclude_item_ids: è¦æ’é™¤çš„å¡ç‰‡ ID åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¾‹å¦‚ç”¨æˆ·è‡ªå®šä¹‰èšç±»ä¸­çš„å¡ç‰‡ï¼‰
    
    è¿”å›:
    - åˆ†ç±»ç»“æœï¼ŒåŒ…å«æ¯ä¸ªæ ‡ç­¾å¯¹åº”çš„èšç±»
    """
    try:
        if not request.labels or len(request.labels) == 0:
            raise HTTPException(status_code=400, detail="labels are required")
        
        result = await classify_by_labels(
            labels=request.labels,
            items_data=request.items_data,
            exclude_item_ids=request.exclude_item_ids,
        )
        
        # ä¿å­˜ç»“æœåˆ°æœ¬åœ°
        try:
            save_multiple_clusters(result.get("clusters", []), result_type="ai-classify")
        except Exception as save_error:
            print(f"[API] Failed to save clustering result: {save_error}")
        
        return {"ok": True, **result}
    except Exception as e:
        print(f"[API] ERROR in classify_by_labels: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/clustering/ai-discover")
async def discover_clusters_api(request: AIDiscoverRequest):
    """
    AI è‡ªå‘ç°èšç±»ï¼ˆä½¿ç”¨ K-means å¯¹æ‰€æœ‰å¡ç‰‡è¿›è¡Œæ— ç›‘ç£èšç±»ï¼‰
    
    è¯·æ±‚å‚æ•°:
    - items_data: æ‰€æœ‰å¡ç‰‡æ•°æ®ï¼ˆéœ€è¦åŒ…å« text_embedding å’Œ image_embeddingï¼‰
    - exclude_item_ids: è¦æ’é™¤çš„å¡ç‰‡ ID åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¾‹å¦‚ç”¨æˆ·è‡ªå®šä¹‰èšç±»ä¸­çš„å¡ç‰‡ï¼‰
    - n_clusters: èšç±»æ•°é‡ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šï¼Œè‡ªåŠ¨ç¡®å®š3-5ç»„ï¼‰
    
    è¿”å›:
    - èšç±»ç»“æœï¼ŒåŒ…å«æ¯ä¸ªèšç±»çš„ä¿¡æ¯ï¼ˆåŒ…æ‹¬ AI ç”Ÿæˆçš„åç§°ï¼‰
    """
    try:
        if not request.items_data:
            raise HTTPException(status_code=400, detail="items_data is required")
        
        result = await discover_clusters(
            items_data=request.items_data,
            exclude_item_ids=request.exclude_item_ids,
            n_clusters=request.n_clusters,
        )
        
        # ä¿å­˜ç»“æœåˆ°æœ¬åœ°
        try:
            save_multiple_clusters(result.get("clusters", []), result_type="ai-discover")
        except Exception as save_error:
            print(f"[API] Failed to save clustering result: {save_error}")
        
        return {"ok": True, **result}
    except Exception as e:
        print(f"[API] ERROR in discover_clusters: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
